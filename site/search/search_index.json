{"config":{"lang":["en"],"separator":"[\\s\\u200b\\-_,:!=\\[\\]()\"`/]+|\\.(?!\\d)|&[lg]t;|(?!\\b)(?=[A-Z][a-z])","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Bioinformatics material","text":"<p>This is an initial deployment of a website focused on understanding fundamental bioinformatics concepts. It's currently under construction, so you might encounter some typos :(. The platform  includes essential materials for Bioinformatics, with a focus on computation. It is organized into four sections: Bioinformatics, Concise statistics, Blog, and DRAC.</p>"},{"location":"#bioinformatics","title":"Bioinformatics","text":"<p>(Under construction): The section contains materials designed to refresh foundational knowledge in Bioinformatics, with an emphasis on understanding core concepts.</p>"},{"location":"#concise-statistics","title":"Concise statistics","text":"<p>(Under construction): This section covers general statistical concepts that may be useful for students.</p>"},{"location":"#blog","title":"Blog","text":"<p>I have compiled general posts here that are useful for both students and researchers.</p>"},{"location":"#drac","title":"DRAC","text":"<p>I have compiled posts that are particularly useful for students and researchers at the Montreal Neurological Institute-Hospital (Neuro) who frequently use DRAC.</p>"},{"location":"support/","title":"Support","text":""},{"location":"support/#become-a-sponsor","title":"Become a Sponsor","text":"<p>Open source projects take time and money. Help support the project by becoming a sponsor. You can add your support at any tier you feel comfortable with. No amount is too little. We also accept one time contributions via PayPal.</p> <p> GitHub Sponsors  PayPal</p>"},{"location":"bioinfo/bioinfo_overview/","title":"Overview","text":"<p>UNDER CONSTRACTION </p> <p>This short book covers fundamental Bioinformatics that help users to hands-on Bioinformatics. </p>"},{"location":"blog/","title":"Index","text":"<p>Here, I have compiled General posts that are useful for students and researchers. </p> <p>Most recent posts are: </p> <ul> <li>Container</li> <li>Login Issues</li> </ul>"},{"location":"blog/2025/02/04/how-to-determine-reference-genome-used-for-alignment-in-bam-file/","title":"How to determine reference genome used for alignment in BAM file","text":"<p>If you want to specify the human genome reference run the following command</p> <p>in the terminal  <pre><code>samtools view -H  file.bam\n</code></pre></p>"},{"location":"blog/2024/10/27/bash-cheat-sheet-i/","title":"Bash cheat sheet I","text":"<p>Here are the bash scripts you frequently use to accomplish your tasks.</p>"},{"location":"blog/2024/10/27/bash-cheat-sheet-i/#user-information","title":"User Information","text":""},{"location":"blog/2024/10/27/bash-cheat-sheet-i/#who-command","title":"<code>who</code> command","text":"<p>It is used to retrieve information about the currently logged-in user on the system. <pre><code>who\n</code></pre></p> <p>It provides the following information: <pre><code>Login name of the user \nUser terminal\nDate &amp; Time of login\nRemote host name of the user\n</code></pre></p>"},{"location":"blog/2024/10/27/bash-cheat-sheet-i/#whoami-command","title":"<code>whoami</code> command","text":"<p>It displays the system\u2019s username: <pre><code>whoami\n</code></pre></p>"},{"location":"blog/2024/10/27/bash-cheat-sheet-i/#id-command","title":"<code>id</code> command","text":"<p>It displays the user identification, including the user ID and group ID:</p> <pre><code>id \n</code></pre>"},{"location":"blog/2024/10/27/bash-cheat-sheet-i/#system-information","title":"System information","text":"<p>To display system and hardware information, you can use <code>uname</code> command with various options.</p> command description <code>uname -a</code> print system information <code>uname -s</code> kernel name <code>uname -r</code> kernel release <code>uname -m</code> system architecture <code>uname -o</code> operation system"},{"location":"blog/2024/10/27/bash-cheat-sheet-i/#file-and-directory-commands","title":"File and directory commands","text":""},{"location":"blog/2024/10/27/bash-cheat-sheet-i/#pwd-command","title":"<code>pwd</code> command","text":"<p>This command displays the current working directory. We often use it with the <code>-P</code> flag, which shows the physical directory without any symbolic links:</p> <pre><code>pwd -P\n</code></pre>"},{"location":"blog/2024/10/27/bash-cheat-sheet-i/#ls-command","title":"<code>ls</code> command","text":"<p>It displays a list of files and directories. <pre><code>ls\n</code></pre> or can use it with the following flags:</p> <pre><code>-a Show all files\n-R list subdirectories recursively\n-r Reverse order\n-t Sort by last modified\n-S Sort by file size, largest first\n-l Use a long listing format\n-1 One file per line\n-m Comma-\u00adsep\u00adarated output\n-Q Quoted output\n</code></pre> <p>The following command displays all files, including hidden ones. <pre><code>ls -a \n</code></pre></p>"},{"location":"blog/2024/10/27/bash-cheat-sheet-i/#mkdir-command","title":"<code>mkdir</code> command","text":"<p><code>mkdir</code> creates the directories <pre><code>mkdir ./folder \n</code></pre> The <code>-p</code> flag can be used to create multiple directories at once.</p> <pre><code>mkdir -p ./folder/folder2/folder3 \n</code></pre>"},{"location":"blog/2024/10/27/bash-cheat-sheet-i/#rm-command","title":"<code>rm</code> command","text":"<p>It removes directories and files. To remove a file, <pre><code>rm file.txt\n</code></pre></p> <p>To remove files forcefully without prompting for confirmation, use the <code>-f</code> flag. <pre><code>rm -f file.txt\n</code></pre></p> <p>To remove a directory, use the <code>-r</code> flag. <pre><code>rm -r folder\n</code></pre></p> <p>To move files or folders forcefully, use the <code>-rf</code> flag. <pre><code>rm -rf folder\n</code></pre></p>"},{"location":"blog/2024/10/27/bash-cheat-sheet-i/#touch-command","title":"<code>touch</code> command","text":"<p>It can be used to create, change, and modify timestamps. The following commands create a file and multiple files, respectively: <pre><code>touch file1.txt\ntouch file2.txt  file3.txt\n</code></pre></p> <p>Change only the modification time. <pre><code>touch -m file2.txt\n</code></pre></p> <p>Change only the access time. <pre><code>touch -a file2.txt\n</code></pre></p> <p>Use the timestamps of other files. <pre><code>touch -r file1.txt file2.txt\n</code></pre></p>"},{"location":"blog/2024/10/27/bash-cheat-sheet-i/#cat-command","title":"<code>cat</code> command","text":"<p>The <code>cat</code> command is used to create single or multiple files, view the contents of a file, concatenate files, and redirect output to the terminal or to files.</p>"},{"location":"blog/2024/10/27/bash-cheat-sheet-i/#how-create-file","title":"How create file","text":"<p>By using the following command, you can create a file and add content. Once you\u2019re done, press <code>Ctrl+D</code>.</p> <p><pre><code>cat &gt; file1.txt\nYou care creating a file\n</code></pre> <code>&gt;</code> is called  overwrite. </p>"},{"location":"blog/2024/10/27/bash-cheat-sheet-i/#how-view-content","title":"How view content","text":"<p>View the content  <pre><code>cat  file1.txt file2.txt\n</code></pre></p>"},{"location":"blog/2024/10/27/bash-cheat-sheet-i/#how-view-content-of-large-file","title":"How view content of large file","text":"<p>If you have a large file that does not fit in the terminal, use <code>more</code> and  <code>less</code></p> <pre><code>cat file.txt | more #show page by page\ncat file.txt | less #show line by line\n</code></pre>"},{"location":"blog/2024/10/27/bash-cheat-sheet-i/#head-and-tail","title":"head and tail","text":"<p>You can use the <code>head</code> command to print the first few lines of its input. The following example shows how to print the first 10 lines.</p> <pre><code>head -10  file.txt \n</code></pre> <p>The <code>tail</code> command is the opposite of head and prints the last few lines of its input.</p> <pre><code>head -10  file.txt \n</code></pre>"},{"location":"blog/2024/10/27/bash-cheat-sheet-i/#wc-command","title":"<code>wc</code> command","text":"<p>The <code>wc</code> command, which stands for 'word count,' has different flags: -l gives the number of lines, -w gives the number of words, and -m gives the number of characters. These flags can be combined to get all the information at once.</p> <pre><code>wc  -l  file.txt \n</code></pre>"},{"location":"blog/2024/10/27/bash-cheat-sheet-i/#sort-command","title":"<code>sort</code> command","text":"<p>The <code>sort</code> command will sort it's input. By default it will sort alphabetically but there are many options available to modify the sorting mechanism. The following code sorts the file based on the second column.</p> <pre><code>sort -t' ' -k2,2 file\n</code></pre> <p>The flags used are: </p> <ul> <li><code>-t</code>: specifies the delimiter (in this case, a space). </li> <li><code>-k</code>: specifies the column for sorting. For example:     <ul> <li><code>-k2</code>: means sorting based on the second column</li> <li><code>-k1,3</code>: means sorting from column 1 through column 3.</li> <li><code>-k1</code>: means sorting from column 1 through the end.</li> </ul> </li> </ul>"},{"location":"blog/2024/10/27/bash-cheat-sheet-i/#echo-command","title":"<code>echo</code> command","text":"<p>It can be used to display the text or message, <pre><code>echo \"First message\"\n</code></pre></p> <p>It has <code>-e</code> flag that enable interpretation of backslash escapes. In the below, <code>\\n</code> make new line. </p> <p><pre><code>echo -e \"First message \\n Second message \"\n</code></pre> You store the result in the a file </p> <pre><code>echo -e \"First message \\n Second message \" &gt; out.txt\ncat out.txt\n</code></pre>"},{"location":"blog/2024/10/27/bash-cheat-sheet-i/#append-vs-overwrite","title":"Append vs overwrite","text":"<p>We know <code>&gt;</code> can be used to create a new file, and by reruning it create a new file. </p> <pre><code>echo -e \"First message \\n Second message \" &gt; out.txt\ncat out.txt\necho -e \"First message \\n Second message \" &gt; out.txt\ncat out.txt\n</code></pre> <p>If you want to append, use <code>&gt;&gt;</code></p> <pre><code>echo -e \"First message \\n Second message \" &gt; out.txt\ncat out.txt\necho -e \"First message \\n Second message \" &gt;&gt; out.txt\ncat out.txt\n</code></pre>"},{"location":"blog/2024/10/27/bash-cheat-sheet-i/#variable","title":"Variable","text":"<p>Instead the file, you can store the value or message in a variable  <pre><code>var1=Welcome\nvar2=20\n</code></pre> To call them just dollar sign before the variable name </p> <pre><code>echo $var1\necho $var2\n</code></pre> <p>You can call variable inside the <code>echo</code> <pre><code>echo \"$var1, I guess your age is $var2\"\n</code></pre></p> <p>What we created are user variable, linux has many variables <pre><code>echo $USER\n</code></pre></p> <p>here we had single wor, but if you assign comlex value, you need single quotes ( ' ) or double quotes ( \" ). </p> <pre><code>var3=\"Welcome to cheat sheet\" \necho $var3\n</code></pre> <p>You use <code>declare -i</code>  to set the type integer,  <pre><code>declare -i var4=20\necho $var4\n\ndeclare -i var5=Welcome\necho $var5\n</code></pre></p> <p>You define it as read only.  <pre><code>declare -r var6=\"WEll\"\nvar6=\"WEll2\"\n</code></pre> To cancel use <code>+</code> <pre><code>declare +r var6=\"WEll\"\nvar6=\"WEll2\"\n</code></pre></p> <p>To determine the type of a variable <pre><code>declare -p $var5\n</code></pre></p>"},{"location":"blog/2024/10/27/bash-cheat-sheet-i/#bash-scripts","title":"bash Scripts","text":"<p>Instead of running a series of Bash commands interactively, we often place them in a file with a <code>.sh</code> file extension. Typically, we include <code>#!/bin/bash</code> at the top of the file, indicating that <code>/bin/bash</code> should be used as the interpreter to execute the script. If you place your script in the <code>~/bin directory</code>, it will be executable, provided <code>~/bin</code> is included in your <code>$PATH</code>. To check if <code>~/bin</code> is in your <code>$PATH</code>, run <code>echo $PATH</code>. If it is not included, you can add it to your <code>~/.bash_profile.</code></p> <pre><code>PATH=$PATH:$HOME/bin\nexport PATH\n</code></pre> <p><code>PATH</code> is an environment variable that contains a list of directories where executable programs are located. When you type a command in the command line, the system searches these directories, as defined by the PATH variable, to find the appropriate program interpreter. To make your script executable, run <code>chmod u+x file.sh</code> or <code>chmod 755 file.sh</code>.</p> <p><pre><code>&gt; test.sh\n#!/bin/bash\necho \"WELCOME TO FIRST SHELL SCRIPT \"\nls\necho \"End of FIRST SHELL SCRIPT \"\n</code></pre> Then run  <pre><code>bash test.sh\n</code></pre></p> <p>Users can modify the environment using the <code>set</code> command. By default, Bash does not handle errors automatically and leaves error handling up to the user. For example, the following commands will run without failing, even if an error occurs:</p> <pre><code>#!/bin/bash\necho $TEMP\necho Hello World\n</code></pre> <p>However, by adding <code>set -u</code>, Bash will treat the use of undefined variables as an error, causing the script to fail. For instance, if <code>$TEMP</code> is not defined, the script will exit with an error.</p> <pre><code>#!/bin/bash\nset -u\necho $TEMP\necho Hello World\n</code></pre> <p>The following is a list of set options that can be used to control error handling in Bash:</p> Set Description <code>set -u</code> Exits script on undefined variables <code>set -x</code> Shows command currently executing <code>set -e</code> Exits script on error <code>set -eo pipefail</code> Exits script on pipeline fail <p>If you create a bash file, paset the following code in it and run it If you create a Bash script, paste the following code into it, and run it <pre><code>#!/bin/bash\nmyfunc | echo Hello World\necho Hi\n</code></pre></p> <p>you get the following <pre><code>Hello World\naa.sh: line 2: myfunc: command not found\nHi\n</code></pre></p> <p>Now, add <code>set -eo pipefail</code> to observe the difference</p> <pre><code>#!/bin/bash\nset -eo pipefail\nmyfunc | echo Hello World\necho Hi\n</code></pre> <pre><code>aa.sh: line 3: myfunc: command not found\nHello World\n</code></pre>"},{"location":"blog/2024/10/27/bash-cheat-sheet-i/#comments","title":"Comments","text":"<p>A comment in a script is a note meant for reference and clarity, and it is not executed. To add a comment, simply use a hash symbol (#); everything following it on the same line will be treated as a comment. Comments can occupy an entire line or be placed at the end of a line of code.</p> <pre><code># First comment\necho \"Welcome\" # Second comment\n</code></pre>"},{"location":"blog/2024/10/27/bash-cheat-sheet-i/#command-subsitution","title":"Command Subsitution","text":"<p>You can store the result of a command in a variable by placing the command within backquotes (`) and assigning it to the variable.</p> <pre><code>myvars=`ls /etc`\necho $myvars\n</code></pre> <p>You can also use <code>$()</code> to store the result of a command in a variable.</p> <pre><code>myvars=$(ls /etc)\necho $myvars\n</code></pre>"},{"location":"blog/2024/10/27/bash-cheat-sheet-i/#statue","title":"Statue","text":"<p>To check the result of the last executed command, use echo <code>$?</code>. If the output is 0, it means the command ran successfully.</p> <pre><code>&gt; AAA\nbash: AAA: command not found\n&gt; echo $?\n127\n&gt; ls \n&gt; echo $?\n0 \n</code></pre> <p>It's important to note that even when an error is encountered, the script will continue running by default. To prevent this and stop execution on errors, use <code>set -e</code>.</p>"},{"location":"blog/2024/10/27/bash-cheat-sheet-i/#global-and-local-environment-variables","title":"Global and Local Environment Variables","text":"<p>To view global environment variables, use the <code>env</code> command. To make environment variables persistent, add them to <code>~/.bashrc</code>. For example, to set a global variable <code>VAR=\"VALUE\"</code>, open <code>.bashrc</code>  ( sudo nano ~/.bashrc) and add the line <code>export VAR=\"VALUE\"</code>. To remove an environment variable, use the unset command. The following command deletes <code>MYVARIABLE</code>:</p> <pre><code>unset MYVARIABLE\n</code></pre>"},{"location":"blog/2024/10/27/bash-cheat-sheet-i/#file-permissions","title":"File permissions","text":"<p>You can define the access levels for files and folders to prevent people from accessing other users\u2019 data without permission.</p>"},{"location":"blog/2024/10/27/bash-cheat-sheet-i/#ownership","title":"Ownership","text":"<p>Each file\\folder has three parts:  u: user\\owner of file who created it.   g: group of user who has access permissions of files\\directories.   o: other users.</p> <p>The following command shows the permissions of files and folders. <pre><code>mkdir folder1\ntouch ./folder1/file.sh\ntouch ./folder1/file1.sh\nls -l ./folder1\nls -l file.sh\n</code></pre></p> <p>You can see it has four parts.  1- first one digit: \"-\" or \"d\" 2- second three digits: it shows the permission of owner.  3- third three digits: designate permissions for the group.  4- fourth three digits: designate permissions for the group. </p>"},{"location":"blog/2024/10/27/bash-cheat-sheet-i/#permissions","title":"Permissions","text":"<p>Each file or folder has three types of owners:  - Read: It gives permission to open  - Write: Permission to modify the contents of  files\\folders.   - Execute: Give permission to run it.  </p> <p>The following shows the indicators of the permissions: <pre><code>  r = read permission = 4\n  w = write permission = 2\n  x = execute permission = 1\n  - = no permission = 0 \n</code></pre></p> <p>The following diagram shows the permissions.</p> Diagram Symbol Number Permission Type --- 0 No Permission --x 1 Execute -w- 2 Write -wx 3 Execute + Write r-- 4 Read r-x 5 Read + Execute rw- 6 Read + Write rwx 7 Read + Write + Execute"},{"location":"blog/2024/10/27/bash-cheat-sheet-i/#change-access","title":"Change access","text":""},{"location":"blog/2024/10/27/bash-cheat-sheet-i/#chmod","title":"chmod","text":"<p>It can be used to change the access mode. This command sets permissions (read, write, execute) on a file or directory for the owner, group, and others.</p> <p><pre><code>chmod [reference][operator][mode] file\\folder\n</code></pre> reference: u,g,o  operator: The plus (\"+\") sign indicates give permission.  The minus (\"-\") sign indicates remove permission.  mode: r,w,x </p> <p>Examples  chmod a+r files:  readable by all   chmod a-r files: cancels the ability for all to read the file   chmod a-rwx cancels all access for all   chmod g+rw files give the group read and write permission   chmod u+rwx files give the owner all permissions  chmod og+rw files give the world and the group read and write permission  </p> <p>The following command is a common command:  chmod 755 file.txt:   Owner can read, write, execute files   Group can read and execute (use) but not change files.  Other can read and execute (use) but not change.  </p>"},{"location":"blog/2024/10/27/bash-cheat-sheet-i/#chown-command","title":"<code>chown</code> command","text":"<p>You can change the user and group. <pre><code>chmod user:group file\\folder\nchmod -R user:group file\\folder\n</code></pre></p> <p>With the <code>-R</code> flag, you can change the ownership of the directory and all its contents recursively.</p>"},{"location":"blog/2024/10/27/bash-cheat-sheet-i/#chgrp-command","title":"<code>chgrp</code> command","text":"<p>It can be used to change the group owner. The <code>chgrp</code> and <code>chown</code> commands use the same system call and are functionally identical.</p> <pre><code>chgrp -R group file\\folder\n</code></pre>"},{"location":"blog/2024/10/27/bash-cheat-sheet-i/#disk-usage","title":"Disk usage","text":"<p>You can use <code>du [option] [file/folder]</code> to check disk usage. The command <code>du ./folder</code> shows the disk usage summary of the <code>/folder</code> directory tree and each of its subdirectories. <code>du -h ./folder</code>:  to o determine the disk usage in a human-readable format.   <code>du -sh ./folder</code>: to find out the total disk usage.   <code>du  -ah /home/</code>: To determine the total disk usage of files and directories.  <code>du  -ah --max-depth 2 /home/</code>: show total disk usage of all files and directories up to a certain depth.  <code>du -ah --exclude=\"*.txt\" /home/</code>: to find the total disk usage of files and directories while excluding files that match a given pattern.</p>"},{"location":"blog/2024/10/27/bash-cheat-sheet-i/#networking","title":"Networking","text":"<p>Display all network information.  <pre><code>ipconfig -a \n</code></pre></p> <p>Test the connection to a remote machine: <pre><code>ping &lt;ip-address&gt; or hostname\n</code></pre></p> <p>Displays active or listening ports. <pre><code>netstat -pnltu\n</code></pre></p>"},{"location":"blog/2024/10/27/bash-cheat-sheet-i/#find-command","title":"<code>find</code> command","text":"<p>You can use find to search for files and directories. The following command searches for <code>.txt</code> files: <pre><code>find ./directory -type f -name '*.txt'\n</code></pre> Search for empty files in the directory:  <pre><code>find ./directory -type f -empty\n</code></pre></p> <p>Search for files with the specified permissions. <pre><code>find ./directory -type f -perm 755\n</code></pre></p> <p>If you are looking for the path of command, use <code>whereis</code>, <pre><code>whereis python3\n</code></pre></p>"},{"location":"blog/2024/10/27/bash-cheat-sheet-i/#wildcards","title":"Wildcards","text":"<p>Wildcards are special characters used to create patterns that match sets of files or directories. Here are the common wildcards:</p> <ul> <li><code>*</code>: Matches zero or more characters.</li> <li><code>?</code>: Matches a single character.</li> <li><code>[]</code>: Matches any character within the specified range.</li> <li><code>!</code>: Excludes characters inside the brackets.</li> <li><code>#</code>: Matches any single numeric character.</li> </ul> <p>Let see some useful example. </p> example descrition d* any file that starts with the letter 'd'. *.txt any file with the .txt extension ??p* any file whose third letter is 'p' *.??? any file with a three letter extension *# or *[0-9] any file that ends with a numeric character. [bd]* any file whose name either begins with  'b' or 'd' [0-9] any file whose name includes a digit in it [a-d]* any file whose name either begins with  'a', 'b', 'c', or 'd' [!a-d]*  any file  which name does not start with 'a-d' [[a-zA-Z0-9]]* any file which name  starts alphanumeric character <p>The following command will match any file with a name that contains an 'a' followed by zero or more characters, then a character that is not 'a', 'b', or 'c', and ending with the '.txt' extension. <pre><code>ls a*[!abc].txt\n</code></pre></p>"},{"location":"blog/2024/10/27/bash-cheat-sheet-i/#search-pattern-in-file","title":"Search pattern in File","text":"<p>You can use <code>grep</code> command to search pattern in file. <code>grep pattern files</code>. The following  search for \"hello\" in the file. <pre><code>grep \"hello\" file.txt \n</code></pre></p> <p>If you want the command to be case-sensitive, use the <code>-i</code> flag. <pre><code>grep -i \"hello\" file.txt\n</code></pre></p>"},{"location":"blog/2024/10/27/bash-cheat-sheet-i/#pwd-command_1","title":"<code>pwd</code> command","text":"<p>It stands for 'print working directory' and is used to display the current working directory.</p>"},{"location":"blog/2024/10/27/bash-cheat-sheet-i/#process-management","title":"Process management","text":""},{"location":"blog/2024/10/27/bash-cheat-sheet-i/#ps-command","title":"<code>ps</code> command","text":"<p>The <code>ps</code> command displays information about a selection of active processes. <pre><code>ps\n</code></pre></p> <p>You can terminate active processes as follows: <pre><code>kill &lt;process_id&gt;\n</code></pre></p>"},{"location":"blog/2024/10/27/bash-cheat-sheet-i/#curl-command","title":"<code>curl</code> Command","text":"<p>This command can be used to transfer data to or from a server. It supports various protocols, including HTTP, HTTPS, FTP, SFTP, etc. You can easily request an HTML page or a file. <pre><code>curl -o aa.htlm  https://saeidamiri1.github.io/\n</code></pre></p> <p>Downloads a file and saves it with the same name as in the URL: <pre><code>curl -O   https://saeidamiri1.github.io/\n</code></pre></p>"},{"location":"blog/2024/10/27/bash-cheat-sheet-i/#handling-http-requests","title":"Handling HTTP Requests","text":"<p>It allows you to send custom HTTP requests using various methods such as GET, POST, PUT, DELETE, etc. For instance, to send a GET request: <pre><code>curl -X GET https://api.example.com/resource\n</code></pre></p> <p>Similarly, to send a POST request with data: <pre><code>curl -X POST -d \"key1=value1&amp;key2=value2\" https://api.example.com/resource\n</code></pre></p> <p>Includes custom headers in the request. <pre><code>curl -H \"Content-Type: application/json\" http://example.com\n</code></pre></p>"},{"location":"blog/2024/10/27/bash-cheat-sheet-i/#uploading-files","title":"Uploading Files","text":"<p>In addition to downloading, you can also upload files using the <code>-T</code> flag. In the following example, the file is uploaded to the server.</p> <pre><code>curl -T uploadfile.txt ftp://example.com/upload/\n</code></pre>"},{"location":"blog/2024/10/27/bash-cheat-sheet-i/#authentication","title":"Authentication","text":"<p>By using the <code>-u</code> flag, you can specify the password. <pre><code>curl -u username:password https://example.com/api\n</code></pre></p>"},{"location":"blog/2024/10/27/bash-cheat-sheet-i/#interrupted","title":"Interrupted","text":"<p>If the download is interrupted for some reason, you can use the <code>-C -</code> flag:</p> <pre><code>curl -C - -O ftp://speedtest.tele2.net/1MB.zip\n</code></pre>"},{"location":"blog/2024/10/27/bash-cheat-sheet-i/#history-command","title":"<code>history</code> Command","text":"<p>The <code>history</code> command displays a list of previously issued commands. There are a couple of options that can be used to modify the history. <pre><code>history -c # clears the entire command history.\nhistory -a # appends the current session's history to the history file.\n</code></pre></p>"},{"location":"blog/2024/10/27/bash-cheat-sheet-i/#useful-references","title":"Useful references","text":"<p>-[ref]:  https://swcarpentry.github.io/shell-novice/</p>"},{"location":"blog/2024/10/27/bash-cheat-sheet-ii/","title":"Bash cheat sheet II","text":"<p>Here we present the continuation of Bash cheat sheet I, providing more advanced Bash commands.</p>"},{"location":"blog/2024/10/27/bash-cheat-sheet-ii/#bash-configuration","title":"Bash Configuration","text":"<p>Linux includes several configuration files that can be used to manage the system. To view the existing Bash configuration files, run the following command.</p> <pre><code>ls -a ~/ | grep bash\n</code></pre>"},{"location":"blog/2024/10/27/bash-cheat-sheet-ii/#bashrc","title":"<code>.bashrc</code>","text":"<p>The <code>.bashrc</code> file is a configuration file (shell script) that runs whenever a shell session is started interactively. When you open a command shell, this file is executed. The purpose of the <code>.bashrc</code> file is to up environment variables, functions, aliases, customize the prompt, and configure other settings that should be applied each time a new terminal window is opened. If you modify the <code>.bashrc</code> file, you can refresh the current shell session without closing the terminal by running <code>source ~/.bashrc</code>.</p>"},{"location":"blog/2024/10/27/bash-cheat-sheet-ii/#bash_profile","title":"<code>.bash_profile</code>","text":"<p>The <code>.bash_profile</code> is executed when you log in interactively through the terminal, while .bashrc is executed for interactive non-login shells. If you make changes to these files, they won't take effect until the next login session. Typically, <code>~/.bash_profile</code> includes commands to source the <code>.bashrc</code> file. This ensures that both files are read and executed each time you log in to the terminal.</p> <p><pre><code>if [[ -f ~/.bashrc ]]; then\n    . ~/.bashrc\nfi\n</code></pre> Note, most Linux distributions are using <code>~/.profile</code> instead of <code>~/.bash_profile</code>. The <code>~/.profile</code> file is read by all shells, while <code>~/.bash_profile</code> only by Bash.</p>"},{"location":"blog/2024/10/27/bash-cheat-sheet-ii/#bash_history","title":"<code>.bash_history</code>","text":"<p>By default, Bash saves the command history in the <code>~/.bash_history</code> file. The history command typically shows commands from the current terminal session. However, the commands saved to <code>~/.bash_history</code> are those from the last session when you log out.</p>"},{"location":"blog/2024/10/27/bash-cheat-sheet-ii/#redirecting-and-piping","title":"Redirecting and piping","text":"<p>The output of any command can be either standard output (stdout) or standard error (stderr), and both can be redirected or discarded as needed. </p>"},{"location":"blog/2024/10/27/bash-cheat-sheet-ii/#redirecting-to-a-file","title":"Redirecting to a file","text":"<p>Using the classic redirection operator (command &gt; file), stdout is redirected to the specified file, while stderr is displayed in the terminal. To redirect stdout to out.log and stderr to err.log, you can use the following commands:</p> <pre><code>command &gt; out.log 2&gt; err.log\n</code></pre> <p>To discard output, redirect it to <code>/dev/null</code>, which acts as a null device where anything sent to it is not stored. For example, to log stdout while hiding errors, use:</p> <pre><code>command  &gt; out.log 2&gt; /dev/null\n</code></pre> <p>To send both stdout and stderr to out.log, use the following command: <pre><code>command&gt; out.log 2&gt;&amp;1 \n</code></pre></p> <p>Alternatively, you can use: <pre><code>command  &amp;&gt; out.log  \n</code></pre></p> <p>so you get no output <pre><code>myprogram &amp;&gt;/dev/null \n</code></pre></p> <p>So, using either of these methods, you will get no output in the terminal because both stdout and stderr are redirected to the out.log file</p> <pre><code>ls -l /bin 2&gt; /dev/null\nls -l /bin/TEST 2&gt; /dev/null\n</code></pre>"},{"location":"blog/2024/10/27/bash-cheat-sheet-ii/#redirecting-from-a-file","title":"Redirecting from a File","text":"<p>To redirect input from a file, you can use (command &lt; file), which sends the contents of a file as input to a command. For example, to understand this, consider the command <code>wc -l</code>: <pre><code>wc -l file.txt\n10 file.txt\n</code></pre> You can redirect a file as input to wc -l by using the &lt; symbol:</p> <p><pre><code>wc -l &lt; file.txt\n10 \n</code></pre> If you want to redirect input to a command and then redirect the result to a file instead of displaying it in the terminal, you can use the following code.</p> <pre><code>wc -l &lt; file.txt &gt; result.out\n</code></pre>"},{"location":"blog/2024/10/27/bash-cheat-sheet-ii/#piping","title":"Piping","text":"<p>To send the output of one command as input to another, we use piping, which has a simple structure: the <code>|</code> symbol is placed between commands. For example, let's run <code>ls</code>. <pre><code>ls \n\nREADME.md               docs                    package.json\nTODO                    material                pyproject.toml\ncodes                   mkdocs.yml              site\ndebug.log               package-lock.json       test.txt\n</code></pre></p> <p>To send the output of one command to another and shorten the result, we use piping with the <code>|</code> symbol between commands <pre><code>ls | head -4\nREADME.md\nTODO\ncodes\ndebug.log\n</code></pre> We can use multiple instances of piping to send the output of one command to another command and continue chaining them as needed. The <code>|</code> symbol is used between commands for this purpose. <pre><code>ls | head -4 | tail -2  \ncodes\ndebug.log\n</code></pre></p> <p>We can take this further by redirecting the output to a file or another location using the <code>&gt;</code> symbol. <pre><code>ls | head -4 | tail -2  &gt; pipe.out\n</code></pre></p>"},{"location":"blog/2024/10/27/bash-cheat-sheet-ii/#arrays","title":"Arrays","text":"<p>You can store multiple values in a single variable, referred to as an array. The structure is simple: enclose the values in parentheses and separate them with spaces. Array indexing starts from 1.</p> <pre><code>myarray=(\"first\" \"second\" \"third\")\necho $myarray\necho ${myarray[1]}\necho ${myarray[2]}\n</code></pre>"},{"location":"blog/2024/10/27/bash-cheat-sheet-ii/#conditional","title":"Conditional","text":"<p>The conditional structure in Bash follows a standard format. The general structure is called an <code>if-elif-else</code> statement, which evaluates a series of conditions that may lead to different paths of execution</p> <pre><code>if &lt;condition1&gt;; then\n    &lt;commands&gt;\nelif &lt;condition2&gt;; then\n    &lt;other_commands&gt;\nelse\n    &lt;fallback_commands&gt;\nfi\n</code></pre> <p>It can also be rewritten as an <code>if-elif</code> statement or an <code>if-else</code> statement. In some cases, we want to execute one of actions if a condition is true, and another if it is false.</p> <pre><code>if &lt;condition1&gt;; then\n    &lt;commands&gt;\nelif &lt;condition2&gt;; then\n    &lt;other_commands&gt;\nfi\n</code></pre> <pre><code>if &lt;condition1&gt;; then\n    &lt;commands&gt;\nelse\n    &lt;fallback_commands&gt;\nfi\n</code></pre> <p>Each conditional statement evaluates a single condition (which can be a combination of multiple conditions) and performs an action (or a series of actions). Let's look at the following example, which tests the number of files in the current directory.</p> <pre><code>VAR=`ls -1 | wc -l` \necho \"Testing the number of files\"\necho \"======================\"\necho \"\"\n\n\nif [[ $VAR -eq 2 ]] then\n        echo \" number of file is 2\"\nelse \n     echo \"number of file is not 2\"\nfi\n</code></pre> <p>You can replace the <code>-eq</code> (numeric comparison) operator with the <code>==</code> (string comparison) operator in some cases.</p>"},{"location":"blog/2024/10/27/bash-cheat-sheet-ii/#number-evaluation","title":"Number evaluation","text":"<p>The following table includes comparison operators that can be used to compare numbers:</p> Expression escription symbol Operators value1 -eg value 2 tests if two values/variables are equal = or == value1 -ne value 2 checks if two values/variables are not equal != value1 -le value 2 checks if one value is equal or less than another &lt;= value1 -lt value 2 checks if one value is less than another &lt; value1 -ge value 2 checks if one value is greater than or equal to another &gt;= value1 -gt value 2 checks if one value is greater than anothe &lt;"},{"location":"blog/2024/10/27/bash-cheat-sheet-ii/#string-evaluation","title":"String evaluation","text":"<p>The following table includes comparison operators that can be used to compare numbers:</p> Expression escription -n string returns true if the length of string is greater than zero -z string returns true if The length of string is zero string1 == string2 The string1 and the string2 are equal string1 != string2 The string1 and the string2 are not equal string1 &lt; string2 The string1 sorts (ASCII) before the string2 string1 &gt; string2 The string1 sorts (ASCII) after the string2"},{"location":"blog/2024/10/27/bash-cheat-sheet-ii/#file-evaluating","title":"File Evaluating","text":"<p>Let's create a test file and check if we can test its existence using a conditional statement. <pre><code>echo \"ABC\" &gt; test.txt\nFILENAME=test.txt1\necho \"Testing for the existence of a file called $FILENAME\"\n\nif [[ ! -a $FILENAME ]]\n    then\n        echo \" $FILENAME does exist \"\nfi\n\n# negation operator \nif [[ ! -a $FILENAME ]]\n    then\n        echo \" $FILENAME does not  exist \"\nfi\n</code></pre></p> <p>The following table presents the operators that allow you to assess and compare files in Bash.</p> Expression Description file1 -nt file2 compares the creation dates of two files to see if one file (file 1) is newer than the other (file 2) file1 -ot file2 compares the creation dates of two files to verify if one file (file 1) is older than the other (file 2) file1 -ef file2 checks if two variables are hard links to the same file -e validates the existence of a file (returns true if a file exists) -f validates if the variable is a regular file (not a folder, directory, or device) -d checks if the variable is a directory -h (or -L) validates if the variable is a file that is a symbolic link -b checks if a variable is a block special file -c verifies if a variable is a character special file -p checks if a file is a pipe -S checks if a file is a socket -s verifies if the size of the file is above zero (returns true if the file is greater than 0 bytes) -t validates if the file is associated with a terminal device -r checks if the file has read permissions -w verifies if the file has write permissions -x checks if the file has execute permissions -g checks if the SGID flag is on a file -u verifies if the SUID flag is on a file -k checks if the sticky bit is on a file -O verifies if you\u2019re the owner of a file -G validates if the group ID is the same as yours -N validates if a file was modified since it was last read"},{"location":"blog/2024/10/27/bash-cheat-sheet-ii/#case-statements","title":"Case Statements","text":"<p>Case statements can be very useful when you want to control the flow of execution based on different conditions.  <pre><code>case &lt;test variable&gt; in\n&lt;test pattern1&gt;)  &lt;perform task&gt;;;\n&lt;test pattern2&gt;) &lt;perform task&gt;;;\n&lt;test pattern3&gt;) &lt;perform task&gt;;;\n\u2026\u2026\u2026\u2026\u2026\nesac\n</code></pre></p> <pre><code>n=`ls -1 | wc -l` \necho $n\n\ncase $n in \n0) echo \"There are no files here \\n\";; \n1) echo \"There is one \\n\";;\n2) echo  \"There are two files here \\n\";; \n3) echo  \"There are three files here \\n\";; \n4) echo  \"There are four files here \\n\";; \n*) echo \"There are more than four files here \\n\";; \nesac\n</code></pre> <p>The pattern <code>*</code> acts as a catch-all and will match if none of the other patterns match.</p> <pre><code>n=`ls -1 | wc -l` \necho $n\n\ncase $n in \n0|2|4) echo \"There are even number of files here \\n\";; \n1|3|) echo \"There are odd number of files here \\n\";;\n*) echo \"There are more than four files here \\n\";; \nesac\n</code></pre>"},{"location":"blog/2024/10/27/bash-cheat-sheet-ii/#control-operator","title":"Control operator","text":"<p>You can combine multiple conditions using <code>&amp;&amp;</code> (and) and <code>||</code> (or) to create alternative logical expressions:</p> <ul> <li> <p><code>&amp;&amp;</code> means execute the statement that follows only if the preceding statement is successful (i.e., it returns an exit code of zero). For example, <code>command1 &amp;&amp; command2</code> will only run command2 if command1 is successful.</p> </li> <li> <p><code>||</code> means execute the statement that follows only if the preceding statement fails (i.e., it returns a non-zero exit code). For example, <code>command1 || command2</code> will only run command2 if command1 fails.</p> </li> </ul> <pre><code>VAR=`ls -1 | wc -l` \necho \"Testing the number of files\"\necho \"======================\"\necho \"\"\n\n\nif [ $VAR -eq 2 ] ||  [ $VAR -eq 3 ] then\n        echo \"number of file is 2 or 3\"\nelse \n  echo \"number of file is not 2 or 3\"\nfi\n</code></pre> <p>The <code>if-else</code> statement can be simplified using <code>||</code> and <code>&amp;&amp;</code>. For example, you can replace an <code>if-else</code> structure with these logical operators to handle success and failure conditions in a more compact form.</p> <pre><code>if &lt;condition1&gt;; then\n    &lt;commands&gt;\nelse\n    &lt;fallback_commands&gt;\nfi\n</code></pre> <pre><code>&lt;condition1&gt; &amp;&amp; &lt;commands&gt; || &lt;fallback_commands&gt;\n</code></pre> <p>Other control operators include:</p> <ul> <li><code>&amp;</code> means execute the preceding statement in the background.</li> <li><code>;</code> execute the preceding statement and, once it completes, proceed to the next statement.</li> <li><code>|</code> or piping: executes the preceding statement and connects its stdout to the stdin of the following statement.</li> </ul>"},{"location":"blog/2024/10/27/bash-cheat-sheet-ii/#loops-in-bash","title":"Loops in Bash","text":"<p>Bash supports different types of loops to repeatedly execute a of commands. By using conditional statements, you can have complex control over the flow of the code.</p>"},{"location":"blog/2024/10/27/bash-cheat-sheet-ii/#for-loop","title":"For Loop","text":"<p>For loops in Bash are used to iterate over a list of items. The general syntax of a <code>for</code> loop is as follows:</p> <pre><code>for &lt;VAR&gt; in &lt;list of item&gt;; do\n    &lt;command&gt;\ndone\n</code></pre> <p>The list of items can be a space-separated list of values or the output of a command that returns a list of items</p> <pre><code>for i in 1 2 3; do\n   echo \"Welcome $i times\"\ndone\n</code></pre> <p>You can define a range of numbers or characters using the sequence expression. For a range of numbers, we often use <code>{START..END..STEP}</code>. For example, <code>{1..10..2}</code> generates 1 3 5 7 9.</p> <pre><code>for i in {1..10..2}; do\n   echo \"Welcome $i times\"\ndone\n</code></pre> <p>You can also use an array to define a list of items:</p> <pre><code>myarray=(aa bb cc)\nfor i in $myarray; do\n   echo \"Welcome $i times\"\ndone\n</code></pre>"},{"location":"blog/2024/10/27/bash-cheat-sheet-ii/#while-loop","title":"While Loop","text":"<p>The <code>while</code> loop is used to execute commands as long as a condition is true. The general syntax for a <code>while</code> loop is as follows:</p> <pre><code>while  &lt;conditions&gt;; do\n    &lt;command&gt;\ndone\n</code></pre> <p>The following runs a list of commands repeatedly as long as a specified condition is true:</p> <pre><code>COUNT=1\nNUM=10\nwhile [[ $COUNT -le $NUM ]]\ndo\n    echo \"repear number $COUNT\"\n    COUNT=\"`expr $COUNT + 1`\"\ndone\n</code></pre> <p>It can be simplified as follows:</p> <pre><code>COUNT=1\nNUM=10\nwhile [[ $COUNT &lt;= $NUM ]]\ndo\n    echo \"repear number $COUNT\"\n    ((COUNT++))\ndone\n</code></pre>"},{"location":"blog/2024/10/27/bash-cheat-sheet-ii/#break-and-continue-statements","title":"<code>break</code> and <code>continue</code> Statements","text":"<p>You can use the <code>break</code> and <code>continue</code> statements to implement complex conditions within loops and control the flow of the code. In the following example, we use break to exit the <code>for</code> loop.</p> <pre><code>for i in {1..10..1}; do\n   echo \"Welcome $i times\"\n   if [ $i -eq 5 ]\n   then\n       break\n   fi \ndone\n</code></pre> <p>Let's look at the following example: when the counter is greater than 6, it skips the rest of the loop.</p> <pre><code>for i in {1..10..1}; do\n   if [ $i -ge 6 ]\n   then\n       continue\n   fi\n   echo \"Welcome $i times\" \ndone\n</code></pre>"},{"location":"blog/2024/10/27/bash-cheat-sheet-ii/#error-handling","title":"Error Handling","text":"<p>In the #statue, we see how to use <code>$?</code> to check the status of the last command., </p> <pre><code>DIRECTORY=./TEMP\ncd $DIRECTORY\n\nif [ $? -eq \"0\" ]; then\n    echo \"Last command was run successfully\"\nelse\n    echo \"Last command was not run successfully\"\nfi\n</code></pre>"},{"location":"blog/2024/10/27/bash-cheat-sheet-ii/#functions","title":"Functions","text":"<p>The structure of a function in Bash is as follows:</p> <pre><code>function name () {\n   &lt;command&gt;\n}\n</code></pre> <pre><code>funcexample () {\n    VAR=`ls -1 | wc -l` \n    echo \"Run from inside\"\n    echo $VAR\n}\n\nfuncexample\n</code></pre> <p>You can pass arguments to a function in Bash. <code>$1</code> represents the first argument, <code>$2</code> the second, and so on. Other special variables include <code>$0</code> (the name of the function), <code>$*</code> (all arguments), and <code>$#</code> (the number of arguments).</p> <pre><code>funcexample () {\n  echo \"First parametr $1\"\n  echo \"Second parametr $2\"  \n  echo \"Name of function is $0\"\n  echo  \"All of arguments $*\"\n  echo \"Number of arguments $#\"\n}\nfuncexample Welcome 10 \n</code></pre> <p>You can use the <code>return</code> statement to return a value from a function in Bash.</p> <pre><code>funcexample () {\n    if [[ $# &gt; 1 ]]; then\n        echo \"You have  $# params\"\n        return $#\n    else\n        echo \"No params\"\n        return NA\n    fi\n}\n\nfuncexample Welcome 10 \n</code></pre>"},{"location":"blog/2024/10/27/container/","title":"Container","text":"<p>A container is a lightweight package of an operating system that allows users to install software and its dependencies in isolated environments (called \u2018containers\u2019), making it a single, portable, shareable, and reproducible package, like Apptainer/Singularity or Docker. Unlike virtual machines, containers are lightweight, fast, and typically run on a Linux-based system. They are often best suited for running one or two applications.</p>"},{"location":"blog/2024/10/27/container/#apptainersingularity","title":"Apptainer/Singularity","text":"<p>Apptainer/Singularity is a free and open-source container framework designed to run scientific applications on HPC-backed resources or any operating system. Unlike Docker, Singularity allows non-privileged users to work with it, making it more suitable for HPC environments. In this guide, we introduce Apptainer/Singularity and demonstrate how to set up and use Singularity. We refer to it simply as Singularity, as it was formerly known, and many users still call it by that name.</p> <p><code>singularity</code> provides a command-line interface (CLI) to interact with containers. Run singularity --help to get an overview of Singularity and ensure it is installed correctly. You can also run the following command to test it.</p> <pre><code>$ singularity run library://godlovedc/funny/lolcow\n _______________________________________\n/ Q: What's the difference between USL  \\\n| and the Titanic? A: The Titanic had a |\n\\ band.                                 /\n ---------------------------------------\n        \\   ^__^\n         \\  (oo)\\_______\n            (__)\\       )\\/\\\n                ||----w |\n                ||     ||\n</code></pre>"},{"location":"blog/2024/10/27/container/#downloading-images","title":"Downloading images","text":"<p>First, create the following folders: <pre><code>mkdir -p  ~/test/data\nmkdir -p  ~/test/singularity\n</code></pre></p> <p>Now download it into the provided folder.</p> <pre><code>cd ~/test/singularity\nsingularity pull docker://godlovedc/lolcow\nls \n</code></pre>"},{"location":"blog/2024/10/27/container/#enter","title":"Enter","text":"<p>You can enter the container <pre><code>$singularity shell lolcow_latest.sif\nSingularity&gt; \n</code></pre></p> <p>Simply type an existing command in the container, e.g., <code>which cowsay</code></p> <pre><code>Singularity&gt; which cowsay\n/usr/games/cowsay\n</code></pre> <p>This method allows you to execute commands within the container.</p> <pre><code>Singularity&gt; cowsay 'I am within'\n\n __________\n&lt; I am within &gt;\n ----------\n        \\   ^__^\n         \\  (oo)\\_______\n            (__)\\       )\\/\\\n                ||----w |\n                ||     ||\n</code></pre> <p>To exit, simply type <code>exit</code>: <pre><code>Singularity&gt; exit\nexit\n</code></pre></p>"},{"location":"blog/2024/10/27/container/#executing","title":"Executing","text":"<p>To execute a containerized command from outside the container, use the <code>exec</code> command. This enables you to run commands within the container. For example: <pre><code>$ singularity exec lolcow_latest.sif cowsay 'I am out'\n __________\n&lt; I am out &gt;\n ----------\n        \\   ^__^\n         \\  (oo)\\_______\n            (__)\\       )\\/\\\n                ||----w |\n                ||     ||\n</code></pre></p>"},{"location":"blog/2024/10/27/container/#redirection","title":"Redirection","text":"<p>You can redirect the output to your local system for further use. <pre><code>singularity exec lolcow_latest.sif cowsay 'I am out' &gt; cowsout\ncat cowsout\n</code></pre></p>"},{"location":"blog/2024/10/27/container/#pipes","title":"Pipes","text":"<p>You can also use pipeline techniques to execute commands with Singularity. <pre><code>cat cowsout | singularity exec lolcow_latest.sif cowsay\n</code></pre></p>"},{"location":"blog/2024/10/27/container/#building-a-container","title":"Building a Container","text":""},{"location":"blog/2024/10/27/container/#creating-a-container","title":"Creating a container","text":"<p>If you\u2019re interested in creating your own container (called a sandbox), start with a Singularity definition file. This is a text file containing a series of instructions used to build a container image. Below is a simple definition file. In this example, we will install Python 3 and create the <code>/mydata</code> directory within the container.</p> <pre><code>cat &lt;&lt;EOF &gt; ubuntu.def\nBootstrap: library\nFrom: ubuntu:latest\n\n%runscript\n echo \"Container was created \\$NOW\"\n\n%environment\n    export LC_ALL=C\n\n%labels\n    AUTHOR saeid.amiri1@gmail.com\n    Version v0.0.1\n\n%post\n    apt-get update &amp;&amp; apt-get -y install python3 \n    mkdir /mydata\nEOF\n</code></pre> <p>The first two lines, <code>Bootstrap: library</code> and <code>From: ubuntu:latest</code>, specify that we want to pull the base image from the <code>library</code>, with the operating system being the latest version of Ubuntu. The rest of the file uses the <code>% prefix</code> to define different stages of the image build process. <code>%runscript</code>,  defines a script that will run when the container is started using the singularity run command. <code>%environment</code>,  defines environment variables for the container. <code>%labels</code> allows you to add metadata such as the author, version, etc. <code>%post</code> this section is where you can install software and pull files from remote locations. There are various options available to help you create an efficient container, see documentaion. </p> <p>By running the following code, you can create your own container. Ensure you have <code>ubuntu.img</code> in the current directory. </p> <pre><code>sudo singularity build --sandbox ubuntu.img ubuntu.def\n</code></pre>"},{"location":"blog/2024/10/27/container/#modify-containers","title":"Modify containers","text":"<p>To modify your container, use <code>shell --writable</code> <pre><code>sudo singularity shell --writable ubuntu.img\n</code></pre></p> <p>Next, install the Nano text editor and write a simple Python script. <pre><code>apt-get update\napt-get install nano\ncd /opt\nnano test.py\nprint(\"A simple code in Python\")\n</code></pre></p>"},{"location":"blog/2024/10/27/container/#test-application","title":"Test application","text":"<p>Run the following command to execute the Python script you created in the container. <pre><code>$ singularity exec  ./ubuntu.img python3 /opt/test.py\nA simple code in Python\n</code></pre></p>"},{"location":"blog/2024/10/27/container/#accessing-host-files","title":"Accessing Host Files","text":"<p>Singularity has access only to files within the container. Therefore, if an application requires access to a specific file, you must mount it.</p> <pre><code>mkdir ./data1\necho 'Create first file' &gt;   ./data1/test11.txt\necho 'Create second file ' &gt; ./data1/test12.txt\n</code></pre> <p>Run the following command to check if the created folder is accessible within the container. By default, all folders stored in the container folder (on the host) are mounted inside the container. <pre><code>$ singularity exec  ./ubuntu.img ls -l  ./data1\ntotal 12\n-rw-rw-r-- 1 sam sam 18 Oct  3 10:59 test11.txt\n-rw-rw-r-- 1 sam sam 20 Oct  3 10:59 test12.txt\n</code></pre></p> <p>If a folder is not in the Singularity folder, you need to mount it using the <code>--bind (-B)</code> flag, which specifies the directories that must be linked between the host and the container. <pre><code>mkdir ../data/data2\necho 'Create third file' &gt; ../data/data2/test21.txt\nsingularity exec  --bind $HOME/test/data/data2 ./ubuntu.img ls -l $HOME/test/data/data2\ntotal 4\n-rw-rw-r-- 1 sam sam 18 Oct  3 11:23 test21.txt\n</code></pre></p> <p>You can bind mount a directory to a destination in the container using the source:destination syntax. By default, Singularity bind mounts several directories into your container, including <code>$HOME</code>, <code>/tmp</code>, <code>/proc</code>, and <code>/dev</code>. For example, to mount the directory <code>$HOME/test/data/data2</code> from the local system to <code>/mydata</code> within the container, use the following syntax: <pre><code>singularity exec  --bind $HOME/test/data/data2:/mydata ./ubuntu.img ls -l /mydata \n</code></pre></p> <p>You can bind multiple folders simultaneously.\u201d <pre><code>mkdir ../data/data3\necho 'Create fourth file' &gt; ../data/data3/test31.txt\n\nsingularity exec  --bind $HOME/test/data/data2:/mydata,$HOME/test/data/data3:/tmp ./ubuntu.img ls -l  /mydata /tmp\n</code></pre></p> <p>You can use the environment variable <code>$SINGULARITY_BINDPATH</code>. <pre><code>export SINGULARITY_BINDPATH=$HOME/test/data/data2:/mydata,$HOME/test/data/data3:/tmp\nsingularity exec  ./ubuntu.img ls -l  /mydata /tmp\n</code></pre></p>"},{"location":"blog/2024/10/27/container/#sharing-with-other","title":"Sharing with other","text":"<p>Once your container is ready, you can create a Singularity Image Format (SIF) file, which takes up less space, and share it with others. <pre><code>sudo singularity build ./ubuntu.sif ./ubuntu.img\n</code></pre></p>"},{"location":"blog/2024/10/27/container/#long-running-instances","title":"Long-running Instances","text":"<p>If you want to run the container as a service for an extended period, which is particularly useful for operating as a web server or managing a database, use an instance to run it in the background. <pre><code>singularity instance start lolcow_latest.sif cowsay 'I am within'\n</code></pre></p> <p>We can use the <code>instance list</code> command to show the currently running instances. <pre><code>singularity instance list \n</code></pre></p> <p>We can connect to running instances using the command <code>instance://&lt;name_of_instance&gt;</code>. <pre><code>singularity shell instance://cowsay \n</code></pre></p> <p>You can stop individual instances by using the command <code>instance stop &lt;name_of_instance&gt;</code> <pre><code>singularity instance stop  cowsay \n</code></pre></p>"},{"location":"blog/2024/10/27/container/#image-cache","title":"Image cache","text":"<p>Singularity does cache downloaded image files, which you can view using the singularity cache command: <pre><code>singularity cache list\n</code></pre></p> <p>You can remove images from the cache by using the <code>singularity cache clean</code> command.</p>"},{"location":"blog/2024/10/27/container/#docker","title":"Docker","text":"<p>While Docker is widely used and has a large user community, it requires root privileges for many of its functions, which can pose security and compatibility challenges in high-performance computing (HPC) environments. Consequently, HPC systems often prefer alternatives that allow for secure, unprivileged containerization.</p>"},{"location":"blog/2024/10/27/container/#useful-references","title":"Useful references","text":"<p>-[ref]:  https://hsf-training.github.io/hsf-training-singularity-webpage/</p>"},{"location":"blog/2024/10/27/how-drop-specific-columns/","title":"How drop specific columns","text":"<p>If you want to remove or keep specific columsn, you can <code>cut</code> command. </p> <p>Let  starts a new session and assigns it a name: <pre><code>cat &lt;&lt;EOF &gt; test.txt\nc1 c2 c3 c4 \n1 2 3 4\n1 2 3 4\n1 2 3 4\nEOF\n</code></pre></p> <p>For an simple case, let use <code>cut</code> to just keep the columns 2 and drop the rest from the text file,  you can use <code>cut -d ' ' -f2 test.txt</code>, here  <code>-d ' '</code> specifies the field delimiter\\space character instead of the tab character, which heresis . In the <code>-f</code> flag you can specifies the specific list of columns that are separated by .  <pre><code>$ cut -d ' ' -f2 test.txt\nc2\n2\n2\n2\n</code></pre> You can add more columns  <pre><code>$ cut -d ' ' -f2,4 test.txt\nc2 c4\n2 4\n2 4\n2 4\n</code></pre></p> <pre><code>$ cut -d ' ' -f 2-4 test.txt\nc2 c3 c4\n2 3 4\n2 3 4\n2 3 4\n</code></pre> <p>Now let revert that action and remove the second columns; use the previous command and add the <code>--complement</code> flag </p> <pre><code>$ cut -d ' ' --complement -f2 test.txt\nc1 c3 c4 \n1 3 4\n1 3 4\n1 3 4\n</code></pre> <pre><code>$ cut -d ' ' --complement -f2,4 test.txt\nc1 c3 \n1 3\n1 3\n1 3\n</code></pre> <p>You can use <code>-c</code>, to  selects only the characters specified.  Below cut command prints characters after 3<sup>rd</sup>. </p> <pre><code>$ cut -c  3-  test.txt\n c2 c3 c4 \n2 3 4\n2 3 4\n2 3 4\n</code></pre> <p>Below cut command prints characters btween 3<sup>rd</sup> and 6<sup>th</sup>.  <pre><code>cut -c  3-6  test.txt\n c2 \n2 3 \n2 3 \n2 3 \n</code></pre></p>"},{"location":"blog/2024/10/27/how-remove-duplicated-lines/","title":"How remove duplicated lines","text":""},{"location":"blog/2024/10/27/how-remove-duplicated-lines/#using-awk","title":"Using <code>awk</code>","text":"<p>Sometimes lines are duplicated in your text file. You can easily remove these duplicates using <code>awk</code></p> <pre><code>awk '!seen[$0]++' files.txt\n</code></pre> <p>By adding the <code>-i inplace</code> flag, the original file is modified directly.</p> <pre><code>awk -i inplace  '!seen[$0]++' files.txt\n</code></pre> <p>To remove duplicate lines based on a specific column, such as the second column, replace <code>!seen[$0]++</code> to <code>!seen[$2]++</code>. </p> <pre><code>awk -i inplace  '!seen[$2]++' files.txt\n</code></pre>"},{"location":"blog/2024/10/27/how-remove-duplicated-lines/#using-sort","title":"Using <code>sort</code>","text":"<p>You can use sort to remove duplicates. The following code sorts the file and selects unique values based on the second column.</p> <pre><code>sort -u -t' ' -k2,2 file\n</code></pre> <p>The flags used are: </p> <ul> <li><code>-u</code>: prints only unique lines. </li> <li><code>-t</code>: specifies the delimiter (in this case, a space). </li> <li><code>-k</code>: specifies the column for sorting. For example:     <ul> <li><code>-k2</code>: means sorting based on the second column</li> <li><code>-k1,3</code>: means sorting from column 1 through column 3.</li> <li><code>-k1</code>: means sorting from column 1 through the end.</li> </ul> </li> </ul>"},{"location":"blog/2024/10/27/how-remove-the-dupclicated-columns/","title":"How remove the dupclicated columns","text":""},{"location":"blog/2024/10/27/how-remove-the-dupclicated-columns/#using-awk","title":"Using <code>awk</code>","text":"<p>Sometimes columns are duplicated in your text file. You can easily remove these duplicates using <code>awk</code></p> <pre><code>awk 'NR==1{for(i=1;i&lt;=NF;i++)b[$i]++&amp;&amp;a[i]}{for(i in a)$i=\"\";gsub(\" +\",\" \")}1' \n</code></pre>"},{"location":"blog/2024/10/27/how-redirect-output-to-sed/","title":"how redirect output to sed","text":"<p>If you want to redirect the out of command,</p> <p>run the following command, which will send everything to sed</p> <pre><code>./script |&amp; sed \n</code></pre>"},{"location":"blog/2024/09/28/cheat-sheet-for-markdown/","title":"Cheat sheet for markdown (Basics)","text":"<p>This Markdown cheat sheet provides a basic overview of all the Markdown.</p>"},{"location":"blog/2024/09/28/cheat-sheet-for-markdown/#heading-1","title":"Heading 1","text":"<p>How:  <pre><code> # Heading 1\n</code></pre></p>"},{"location":"blog/2024/09/28/cheat-sheet-for-markdown/#heading-2","title":"Heading 2","text":"<p>How:  <pre><code> ## Heading 2\n</code></pre></p>"},{"location":"blog/2024/09/28/cheat-sheet-for-markdown/#heading-3","title":"Heading 3","text":"<p>How:  <pre><code> ### Heading 3\n</code></pre></p>"},{"location":"blog/2024/09/28/cheat-sheet-for-markdown/#heading-4","title":"Heading 4","text":"<p>How:  <pre><code> #### Heading 4\n</code></pre></p>"},{"location":"blog/2024/09/28/cheat-sheet-for-markdown/#heading-5","title":"Heading 5","text":"<p>How:  <pre><code> ##### Heading 5\n</code></pre></p>"},{"location":"blog/2024/09/28/cheat-sheet-for-markdown/#emphasis","title":"Emphasis","text":"<p>Italic text How: <pre><code> *Italic text* or _Italic text_\n</code></pre> Bold text How: <pre><code> **Bold text** or __Bold text__\n</code></pre></p> <p>Highlight</p> <p>How: <pre><code>==Highlight==\n</code></pre></p> <p>Strikethrough</p> <p>How: <pre><code>~~Strikethrough~~\n</code></pre></p> <p>blockquote</p> <p>nested blockquote</p> <p>How: <pre><code>&gt; blockquote\n&gt;&gt; nested blockquote\n</code></pre></p> <p>Color</p> <p>How:  <pre><code>&lt;span style=\"color:red\"&gt;Color&lt;/span&gt;\n</code></pre></p>"},{"location":"blog/2024/09/28/cheat-sheet-for-markdown/#link","title":"Link","text":"<p>Link</p> <p>How:  <pre><code>[Link](http://www.google.com/)\n</code></pre></p>"},{"location":"blog/2024/09/28/cheat-sheet-for-markdown/#code","title":"Code","text":"<p>inline <code>code</code> multiple lines of <code>codes</code></p> <p>How: <pre><code> `code`   \n    ```\n       codes\n    ```\n</code></pre></p>"},{"location":"blog/2024/09/28/cheat-sheet-for-markdown/#list","title":"List","text":"<p>Unordered List </p> <ul> <li> Bullet     <ul> <li>sub bullet</li> <ul> <li>sub sub bullet</li> </ul> <li>sub bullet</li> </ul> </li> </ul> <p>How: <pre><code>Unordered List\n- Bullet\n  - sub bullet\n    -  sub sub bullet\n  - sub bullet\n</code></pre></p> <ol> <li>Numbered list<ol> <li>Sub numbered list</li> <li>Sub numbered kist</li> </ol> </li> </ol> <p>How: <pre><code>1. Numbered list\n    1. Sub numbered list\n    2. Sub numbered kist\n</code></pre></p> <p>Task List - [ ] An uncompleted task - [x] A completed task</p> <p>How: <pre><code>- [ ] An uncompleted task\n- [x] A completed task\n</code></pre></p> <p>Horizontal line :</p> <p>How: <pre><code>-----\n</code></pre></p>"},{"location":"blog/2024/09/28/cheat-sheet-for-markdown/#latex","title":"Latex","text":"<p>LATEX</p> <p></p> <p></p> <p>How: <pre><code>![E_0=mc^2](https://latex.codecogs.com/svg.latex?E_0=mc^2)\n\n&lt;img src=\"https://tex.s2cms.ru/svg/E_0=mc^2\" alt=\"E_0=mc^2\" /&gt;\n</code></pre></p>"},{"location":"blog/2024/09/28/cheat-sheet-for-markdown/#table","title":"Table","text":"<p>Table:</p> header 1 header 2 Row 1 Values Row 2  continue Values <p>How: <pre><code>header 1  | header 2\n-------   | -------\nRow 1     |  Values\nRow 2 &lt;br&gt; continue    |  Values\n</code></pre></p>"},{"location":"blog/2024/09/28/cheat-sheet-for-markdown/#image","title":"Image","text":"<p>Image:</p> <p></p> <p>How: <pre><code>![picture](https://raw.githubusercontent.com/saeidamiri1/saeidamiri1.github.io/master/public/favicon.ico)\n</code></pre></p>"},{"location":"blog/2024/09/28/cheat-sheet-for-markdown/#foldable-text","title":"Foldable text","text":"Hidden materials <p> Put text here </p> <p>How: <pre><code>&lt;details&gt;\n&lt;summary&gt;Hidden materials&lt;/summary&gt;\n&lt;p&gt; Put text here &lt;/p&gt;\n&lt;/details&gt;\n</code></pre></p>"},{"location":"blog/2024/09/28/cheat-sheet-for-markdown/#emoji-and-hotkey","title":"Emoji and Hotkey","text":"<p>How: <pre><code>  :+1:\n</code></pre> The complete list can be found at emoji list</p> <p>Hotkey: \u2318C</p> <p>How: <pre><code>  &lt;kbd&gt;\u2318C&lt;/kbd&gt;\n</code></pre></p> <p>common hotkey: \u2325(Option)\u2303(Control)\u2318(Command)\u21e7(Shift)\u21ea(Caps Lock) \u21e5(Tab) \u21a9(Return) \u232b(Delete)\u2191(Up)\u2193(Down)\u2190(Left)\u2192 (right)</p>"},{"location":"blog/2024/09/28/cheat-sheet-for-markdown/#miscellaneous","title":"miscellaneous","text":""},{"location":"blog/2024/09/28/cheat-sheet-for-markdown/#comment","title":"Comment","text":"<p>How: <pre><code>&lt;!--\n Does not show\n--&gt;\n</code></pre></p>"},{"location":"blog/2024/09/28/cheat-sheet-for-markdown/#indent","title":"indent","text":"<p>\u00a0 with indent </p> <p>How:  <pre><code>&amp;nbsp; with indent \n</code></pre></p>"},{"location":"blog/2024/09/28/cheat-sheet-for-markdown/#footnotes","title":"Footnotes","text":"<p>Need more <sup>1</sup> to say.</p>"},{"location":"blog/2024/09/28/cheat-sheet-for-markdown/#new-line","title":"New line","text":"<p> How:  <pre><code>&lt;br/&gt;\n</code></pre></p>"},{"location":"blog/2024/09/28/cheat-sheet-for-markdown/#useful-references","title":"Useful references","text":"<p>-[ref1]:  https://github.com/adam-p/markdown-here/wiki/Markdown-Cheatsheet</p> <ol> <li> <p>This is the Footnote.\u00a0\u21a9</p> </li> </ol>"},{"location":"blog/2024/10/27/passwordless-ssh/","title":"passwordless ssh","text":"<p>We often use SSH (Secure Shell) to remotely connect to servers via the terminal. If you\u2019re tired of entering a password every time you log in, follow the steps below to enable passwordless login.</p>"},{"location":"blog/2024/10/27/passwordless-ssh/#add-server-info-to-config-file","title":"Add server info to config file","text":"<p>Open the SSH configuration file on your PC (the SSH client). <pre><code>vim $HOME/.ssh/config\n</code></pre></p> <p>Add the server name, IP address (hostname), and the user ID for the server to the configuration file: <pre><code>Host server1\nHostName 8.8.8.8\nUser usr1\n</code></pre></p>"},{"location":"blog/2024/10/27/passwordless-ssh/#generate-ssh-key","title":"generate ssh key","text":"<p>Run the following command to generate new SSH keys: <pre><code>ssh-keygen -t rsa\n</code></pre></p>"},{"location":"blog/2024/10/27/passwordless-ssh/#copy-key-to-server","title":"copy key to server","text":"<p>Run the following command to copy the key to server1, and enter your password when prompted: <pre><code>ssh-copy-id server1\n</code></pre></p> <p>You should now be able to log in to the server without entering a password. <pre><code>ssh server1\n</code></pre></p> <p>Note: if you are using powershell in windows, use <code>cat ~/.ssh/id_rsa.pub | ssh usr1@HostName \"mkdir ~/.ssh; cat &gt;&gt; ~/.ssh/authorized_keys\"</code></p>"},{"location":"blog/2024/10/27/screen-session/","title":"<code>screen</code> session","text":"<p>The <code>screen</code> session is a powerful command enables you to push running terminal applications to the background and bring them back to the foreground as needed. When using the <code>screen</code> command, processes can be detached from the session and reattached later. While the session is detached, the original process continues to run, managed by screen. When reattached, the session resumes with terminals intact, just as they were left. Additionally, screen supports split-screen displays and functions seamlessly over SSH connections, even after disconnection and reconnection.</p> <p>Starts a new session and assigns it a name: <pre><code>screen -S test\n</code></pre></p> <p>Displays the list of sessions. <pre><code>screen -ls\n</code></pre></p> <p>Load the session  <pre><code>screen -r &lt;session_name&gt; \n</code></pre></p> <p>Forces detachment from another session. <pre><code>screen -dr &lt;session_name&gt;\n</code></pre></p> <p>Quits the screen session from outside the session. <pre><code>screen -XS &lt;session-name&gt; quit\n</code></pre></p> <p>Display the current session name:  <pre><code>echo $STY\n</code></pre></p> <p>You can split window vertically </p> <pre><code>Ctrl-a, Shift S # created vertical \nCtrl-a, Tab # move to another window\nCtrl-a, c # create new session\nCtrl-a, Shift X # close the window. \n</code></pre> <p>The following shows the shortcut and its action.</p> shortcut action Ctrl-a Ctrl-d Detach from the screen session Ctrl-a c Create a new window inside the screen session Ctrl-a a Switch to the window that you were previously on Ctrl-a \" List all open windows. Double-quotes \" are typed with the Shift key Ctrl-a Space Switch to the next window Ctrl-d Exit out of the current window Ctrl-a  Ctrl-esc How to scroll up and down"},{"location":"blog/2024/10/27/simple-static-website/","title":"simple static website","text":"<p>If you want to create a simple static website on GitHub, you can explore the following options:</p>"},{"location":"blog/2024/10/27/simple-static-website/#mkdocs","title":"MkDocs","text":"<p>MkDocs is a simple yet powerful static site generator written in Python. It allows you to create advanced static sites by preparing your documentation in standard Markdown format and feeding it into MkDocs.</p> <p>For theming for software,  you can use a simple theme like the MkDocs Bootswatch Themes. To get started with installation, follow the installation here.</p>"},{"location":"blog/2024/10/27/simple-static-website/#orderedlist","title":"orderedlist","text":"<p>The orderedlist minimal for GitHub Pages is built using HTML, and you can customize it with basic HTML knowledge. You can create your own copy and modify the [index.html] file to suit your needs. An example of a site using this theme can be found at DS-python-data-analysis.</p>"},{"location":"blog/2024/10/27/tr-command/","title":"<code>tr</code> command","text":"<p>The <code>tr</code> command is very useful command in deleteing or replaceing character</p>"},{"location":"blog/2024/10/27/tr-command/#replace-newline-with-comma","title":"Replace Newline with Comma","text":"<p>Let  starts a new session and assigns it a name: <pre><code>cat &lt;&lt;EOF &gt; test.txt\nc1 c2 c3 c4 \n1 2 3 4\n1 2 3 4\n1 2 3 4\nEOF\n</code></pre></p> <p>Run <code>cat test.txt | tr -s '\\n' ','</code>,  the <code>-s</code> flag determina what you wan to replace, here we interestted in new line <code>\\n</code> </p> <pre><code>% cat test.txt | tr -s '\\n' ','\nc1 c2 c3 c4 ,1 2 3 4,1 2 3 4,1 2 3 4,%    \n</code></pre>"},{"location":"blog/2024/10/27/tr-command/#drop-repeated-spaces","title":"drop repeated spaces","text":"<p>We use <code>tr -s ' '</code> to convert any repeated spaces into a single space:  <pre><code>cat &lt;&lt;EOF &gt; test2.txt\nc1 c2 c3    c4 \n1 2 3 4\n1 2 3 4\n1 2 3 4\nEOF\n</code></pre> cat test.txt | tr -s ' ' <pre><code>$ cat   test2.txt\nc1 c2 c3    c4 \n1 2 3 4\n1 2 3 4\n1 2 3 4\n$ cat test.txt | tr -s ' '\nc1 c2 c3 c4 \n1 2 3 4\n1 2 3 4\n1 2 3 4\nsamamiri@beluga1:~$ \n</code></pre></p>"},{"location":"blog/2024/10/27/tr-command/#specified-characters","title":"specified characters","text":"<pre><code>$ cat test.txt | tr  \"c1\" \"C5\"\nC5 C2 C3 C4 \n5 2 3 4\n5 2 3 4\n5 2 3 4\n</code></pre> <p>Let drop the digitals from file  <pre><code> cat test.txt | tr -d [:digit:]\nc c c c \n</code></pre></p> <p>Or invertly keep the digital  <pre><code> cat test.txt | tr -cd [:digit:]\n 1234123412341234\n</code></pre></p> <p>To convert characters from lower case to upper case, you can either specify a range of characters or use the predefined character classes. </p> <pre><code>echo \"hello\" | tr [:lower:] [:upper:]\nHELLO\necho \"Hello\" | tr [:upper:] [:lower:] \nhello\n</code></pre>"},{"location":"drac/","title":"Index","text":"<p>Here, I have compiled posts that are useful for students and researchers at the Montreal Neurological Institute-Hospital (Neuro) who often use DRAC. </p> <p>Most recent posts are: </p> <ul> <li>How I work with HPC</li> <li>Login issue in DRAC</li> </ul>"},{"location":"drac/2024/11/16/managing-account-in-drac/","title":"Managing Account in DRAC","text":""},{"location":"drac/2024/11/16/managing-account-in-drac/#how-to-create-an-account","title":"How to create an account","text":"<ol> <li>Register for account with the Digital Research Alliance of Canada (DRAC).  </li> <li> <p>For sponsored roles, you will need your supervisor\u2019s CCI. The sponsor will need to confirm the request before you can access the resources. </p> </li> <li> <p>The information to fill in the form should look as follows:</p> <ul> <li>Institution: Calcul Qu\u00e9bec: McGill University</li> <li>Department: Human Genetics (see NOTE below)</li> <li>Position. Master\u2019s Student (choose appropriate option)</li> <li>Sponsor\u00a0: supervisor\u2019s CCI</li> <li>Make this role primary? Yes</li> <li>Disable old roles? No</li> </ul> </li> </ol> <p>NOTE: your department affiliation can also be Neurology, Medicine, etc. If           you\u2019re unsure, put \u201cNeurology\u201d</p> <ol> <li> <p>You can add new roles to an existing account by logging in to your account, then going to My Account &gt; Apply for a New Role. Enter the required information as listed above, and enter the new CCI.  </p> </li> <li> <p>Wait until you receive mail confirmation that your account is now active. If you are unsure, send a message to neurobioinfo@mcgill.ca</p> </li> <li> <p>Log in to your DRAC account to find your username</p> </li> <li> <p>Top of page: \u201cAccount for First_Name Last_Name (CCI: abc-123, Username: user)\u201d  </p> </li> <li> <p>The address for a particular resource, along with its specs, can be found on the DRAC Wiki (left menu, under \u2018Resources\u2019).  </p> </li> <li> <p>Beluga: beluga.computecanada.ca</p> </li> <li> <p>To access the resources, you will need an SSH client.</p> </li> <li> <p>Windows: Download PuTTY. Insert the relevant info into the GUI.  </p> <ol> <li>Hostname: beluga.computecanada.ca </li> <li>port: 22</li> </ol> </li> <li> <p>Linux / Mac:</p> <ol> <li> <p>Open a terminal (Ctrl + alt + T, or \u2318+T).</p> </li> <li> <p>ssh beluga.computecanada.ca</p> </li> </ol> </li> <li> <p>As of April 2024, all DRAC (i.e. Compute Canada) servers require multifactor authentication. See the official documentation for how to set that up. </p> </li> </ol>"},{"location":"drac/2024/11/16/managing-account-in-drac/#after-your-account-has-been-activated","title":"AFTER YOUR ACCOUNT HAS BEEN ACTIVATED","text":"<ol> <li> <p>Default user profiles, software environment and common links:</p> </li> <li> <p>Common links: </p> <ol> <li>We have created links to several key shared directories, containing such things as common software, data and analysis directories.   </li> <li>You can copy them to your own home directory for ease of access.  </li> </ol> </li> <li> <p>Default user profiles:  </p> <ol> <li>We have created several default configuration files. These are used to set environment variables, create common aliases and functions, and set other parameters which will help you work more safely and easily in our shared software environment.   </li> <li>You can copy them to your own home directory and they will be loaded automatically at each subsequent login.  </li> <li>Pro tip: you can create your own environment variables, command aliases and custom functions by adding them to your linux shell config files, e.g. ~/.bash_profile or ~/.bashrc  </li> </ol> </li> <li> <p>Default software environment:   </p> <ol> <li>We have installed a large number of libraries, standalone programs, as well as modules and packages for standard programs such as R, python and perl.   </li> <li>If you copy the configuration files and links from the previous steps, you should be able to access all the common software, starting from the ~/soft (/home/$USER/soft) directory  </li> </ol> </li> <li> <p>Simple command to copy all default config files and links    ```{verbatim}</p> <ol> <li>cp -a /lustre03/project/6001220/COMMON/{.[a-z]*,*} ~/   ```</li> <li>Run this command in your terminal, after you have connected to beluga</li> </ol> </li> <li> <p>Common DOs and DON\u2019Ts</p> </li> <li> <p>DO</p> <ol> <li> <p>Create your own subfolder in the shared ~/runs folder  </p> <ol> <li>Use this folder to store your commands, logs and analysis final results  </li> <li>It will make it easier later for others to access your analyses, while ensuring that they are safe from accidental deletion</li> </ol> </li> <li> <p>Store large temporary input files for your analyses in your <code>$SCRATCH</code> folder (<code>/scratch/$USER</code>)  </p> <ol> <li>Our group has limited /project space; it should be used for semi-permanent storage only, i.e. the duration of a project</li> </ol> </li> <li> <p>Copy your raw data from its source on the <code>/nearline</code> filesystem, to your destination on the /project or /scratch (preferred) filesystems</p> </li> </ol> </li> <li> <p>DON\u2019T</p> <ol> <li>Use the <code>/nearline</code> filesystem for any file operations, except as a source from which to copy raw data  <ol> <li>Do not use <code>/nearline</code> files directly as inputs for any program. This filesystem is intended only for long-term data archiving</li> </ol> </li> </ol> </li> </ol>"},{"location":"drac/2024/11/16/managing-account-in-drac/#some-guidelines-onn-the-use-of-shared-space","title":"Some guidelines onn the use of shared space","text":"<p>1-  /project space is for medium-term storage of final results, or key files for long-term ongoing projects. Your raw inputs and intermediary files should all be on the /scratch filesystem, where they will be automatically deleted after 60 days of disuse. All your analyses should be run on /scratch. </p> <p>2-  For the files you will store on /project, please create your own subfolder in the shared ~/runs folder (absolute path: /project/rrg-grouleau-ac/COMMON/runs). Use this folder to store your commands, logs and analysis final results. It will make it easier later for others to access your analyses, while ensuring that they are safe from accidental deletion. </p> <p>3- The command disksuage_explorer is a great way to search through your files to find what\u2019s using the most space. If your /project data is stored in ~/runs as suggested in point #2, try the following command:  /project/rrg-grouleau-ac/COMMON/runs/[your folder]  This will sort your folders by size with largest on top; you can interactively navigate to quickly see what is using so much space</p> <p>4-  For any projects which have already been completed/published, there should be virtually nothing left in /project space - certainly no large files. If your publication  mandates data sharing, make sure that the files to share a) have already been deposited in whatever online depository is required, and/or b) are all archived on  /nearline. If a project is complete, consider compressing all long-term files into an indexed archive file . Not only will this save /project space, but it will also make it easy to archive to /nearline and restore should someone want it later.</p> <p>5- When cleaning up your /project space, don't just blindly copy all your files en masse to /nearline; we're very limited in space there too!</p> <p>6-  Often the biggest space-eaters are alignments (bam/cram files) and raw read  data (fastq/bam). There is almost never a good reason to keep these files on  /project - if you\u2019re analyzing them, they should be on /scratch. If you\u2019re done with  them, they should either be archived on /nearline, or just plain deleted!</p> <p>7-  If you have any large files you want to keep, make sure they are in a compressed format. i.e. any large vcf files you are using should absolutely be compressed  (gzip/bzip etc.).</p> <p>8- Any large intermediate files should be deleted. For e.g. if you're running plink/SKAT and you have tons of genotype files or vcf files from intermediate  cleanup + imputation steps, delete them! In fact, intermediate files should only exist on /scratch because that\u2019s where you should be running our analyses!</p>"},{"location":"drac/2024/10/27/login-issues/","title":"Login Issues","text":"<p>If you're unable to log in to DRAC or if it gets stuck after entering your credentials, first check the status page for any reported incidents. If none are reported, the issue may be due to system slowness, which DRAC may be able to resolve. If you are still in the terminal, press Ctrl+C to interrupt, then try logging in again and performing basic operations, as the system may be slow.</p>"},{"location":"drac/2024/11/16/hail/","title":"Hail","text":"<p>Hail module is an open-source, scalable framework for exploring and analyzing genomic data which is a module in Python on the top of Apache Spark.. For more detail, refer to its tutorial.</p>"},{"location":"drac/2024/11/16/hail/#how-to-run-on-beluga","title":"How to run on Beluga","text":""},{"location":"drac/2024/11/16/hail/#load-java","title":"Load Java","text":"<pre><code>module load StdEnv/2020\nmodule load java/11.0.2\n</code></pre>"},{"location":"drac/2024/11/16/hail/#path-of-hail-and-spark","title":"Path of Hail and Spark","text":"<pre><code>base_hail=/lustre03/project/6004655/COMMUN/runs/samamiri/general_files/hail\nexport SPARK_HOME=$base_hail/spark-3.1.3-bin-hadoop3.2\n</code></pre>"},{"location":"drac/2024/11/16/hail/#path-of-log-files","title":"Path of Log files","text":"<pre><code>export SPARK_LOG_DIR=$HOME\n</code></pre>"},{"location":"drac/2024/11/16/hail/#start-spark","title":"Start Spark","text":"<pre><code>${SPARK_HOME}/sbin/start-master.sh\n</code></pre>"},{"location":"drac/2024/11/16/hail/#activate-python-environment","title":"Activate Python environment","text":"<pre><code>source ${base_hail}/hail_env2/bin/activate\nexport PYTHONPATH=$base_hail/hail_env2/lib/python3.10/site-packages\nmodule  load python/3.10.2  \n</code></pre>"},{"location":"drac/2024/11/16/hail/#run-python","title":"Run Python","text":"<pre><code>${base_hail}/hail_env2/bin/python3.10\n</code></pre>"},{"location":"drac/2024/11/16/hail/#import-hail","title":"import hail","text":"<pre><code>import hail as hl\n</code></pre> <p>To check if the Hail module is loaded correctly in your Python environment, you can run a simple test script. Here's an example:</p> <pre><code>&gt;&gt;&gt; import hail as hl\n&gt;&gt;&gt; hl.init()\nPicked up JAVA_TOOL_OPTIONS: -Xmx2g\nPicked up JAVA_TOOL_OPTIONS: -Xmx2g\nWARNING: An illegal reflective access operation has occurred\nWARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/lustre03/project/6004655/COMMUN/runs/samamiri/general_files/hail/spark-3.1.3-bin-hadoop3.2/jars/spark-unsafe_2.12-3.1.3.jar) to constructor java.nio.DirectByteBuffer(long,int)\nWARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\nWARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\nWARNING: All illegal access operations will be denied in a future release\n2024-11-15 10:11:27.033 WARN  NativeCodeLoader:60 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\nSetting default log level to \"WARN\".\nTo adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\nRunning on Apache Spark version 3.1.3\nSparkUI available at http://beluga3.int.ets1.calculquebec.ca:4040\nWelcome to\n     __  __     &lt;&gt;__\n    / /_/ /__  __/ /\n   / __  / _ `/ / /\n  /_/ /_/\\_,_/_/_/   version 0.2.109-b71b065e4bb6\nLOGGING: writing to /lustre03/project/6004655/COMMUN/runs/samamiri/general_files/hail/hail_env1/hail-20241115-1011-0.2.109-b71b065e4bb6.log\n</code></pre> <p>If Hail loads correctly, you should see the initialization message from Hail. </p>"},{"location":"drac/2024/10/28/how-i-work-with-hpc/","title":"How I work with HPC","text":"<p>I want to share my expering of using HPC, as mr my day-to-day server for all my needs, you need 1- editor and 2- a cloud storage browser, what I use vscode and cyberducks</p>"},{"location":"drac/2024/10/28/how-i-work-with-hpc/#vscode","title":"vscode","text":"<p>Current research, especially for Bioinformatics, the coding may not be done solely using a specifics programming language e.g., R and will likely use different programming languages; hence, having a modern integrated development environment (IDE) is very important. Vscode editor is a modern IDE that is developed by microsoft. I used it as text editor and coding, I am pretty sure you will like.  Do the following steps to have a standard editor. </p>"},{"location":"drac/2024/10/28/how-i-work-with-hpc/#connect-to-github","title":"connect to github","text":"<p>To save your setting and have the extension from every where connect your editor to Github. </p>"},{"location":"drac/2024/10/28/how-i-work-with-hpc/#install","title":"Install","text":"<p>install the extension <code>Remote - SSH</code>,  <code>Remote - Tunnels</code>,  and <code>Remote - SSH: Editing Configuration Files</code>, you can find right extension for you need, for instance, if you you want to use python, install <code>python</code> extension by microsoft. </p>"},{"location":"drac/2024/10/28/how-i-work-with-hpc/#shortcut","title":"shortcut","text":"<p>vscode has many useful shortcut, they are accessble via <code>setting &gt; keyboard shortcuts</code>, you can change them. </p>"},{"location":"drac/2024/10/28/how-i-work-with-hpc/#termianl","title":"termianl","text":"<p>There is a menu that is called terminal,  you can use it to add a terminal in the below of editor </p>"},{"location":"drac/2024/10/28/how-i-work-with-hpc/#cyberducks","title":"cyberducks","text":""},{"location":"drac/2024/03/26/how/","title":"How","text":"<p>To install your Python module, refer to DRAC, and follow the steps below:</p>"},{"location":"drac/2024/03/26/how/#load-modules","title":"Load modules","text":"<pre><code>module load StdEnv/2023\nmodule load python/3.10  \n</code></pre>"},{"location":"drac/2024/03/26/how/#create-your-own-path","title":"Create your own path","text":"<p>Choose or create the appropriate path (choose a path that you have enough space) for installing the R library <pre><code>mkdir -p /lustre03/project/6004655/COMMUN/runs/[Your ACCOUNT]/Python/MYENV\n</code></pre></p>"},{"location":"drac/2024/03/26/how/#create-a-virtual-environment","title":"Create a virtual environment","text":"<pre><code>virtualenv --no-download  /lustre03/project/6004655/COMMUN/runs/[Your ACCOUNT]/Python/MYENV\n</code></pre>"},{"location":"drac/2024/03/26/how/#activate","title":"Activate","text":"<pre><code>PYTHONENV0=/lustre03/project/6004655/COMMUN/runs/sanjath/MYENV\nsource $PYTHONENV0/bin/activate\nexport PYTHONPATH=$PYTHONENV0/lib/python3.10/site-packages\n</code></pre>"},{"location":"drac/2024/03/26/how/#update-pip","title":"Update pip","text":"<pre><code>$PYTHONENV0/bin/python3.8 -m pip install --no-index --upgrade pip\n</code></pre>"},{"location":"drac/2024/03/26/how/#install-modules","title":"Install modules","text":"<p>By running the following code, the module will be installed in the virtual environment.  <pre><code>$PYTHONENV0/bin/python3.8 -m pip install  matplotlib\n</code></pre></p>"},{"location":"drac/2024/03/26/how/#to-run-python","title":"To run Python","text":"<pre><code>$PYTHONENV0/bin/python3.8\n</code></pre>"},{"location":"drac/2024/03/26/how/","title":"How","text":"<p>To install your R module, refer to DRAC, and follow the steps below:</p>"},{"location":"drac/2024/03/26/how/#load-modules","title":"Load modules","text":"<pre><code>module load StdEnv/2023\nmodule load r/4.4.0  \n</code></pre>"},{"location":"drac/2024/03/26/how/#create-your-own-path","title":"Create your own path","text":"<p>Choose or create the appropriate path (choose a path that you have enough space) for installing the R library <pre><code>mkdir -p /lustre03/project/6004655/COMMUN/runs/[Your ACCOUNT]/R/4.4\n</code></pre></p>"},{"location":"drac/2024/03/26/how/#export-path","title":"Export path","text":"<pre><code>export R_LIBS=/lustre03/project/6004655/COMMUN/runs/[Your ACCOUNT]/R/4.4\n</code></pre>"},{"location":"drac/2024/03/26/how/#run","title":"Run","text":"<pre><code>R \n&gt; .libPaths()\n&gt; # if it is no loaded, load from inside \n&gt; R_LIB_PATH=\"/lustre03/project/6004655/COMMUN/runs/[Your ACCOUNT]/R/4.4\";.libPaths(R_LIB_PATH) \n&gt; # You can install it in \n&gt; install.packages('sp', repos='https://cloud.r-project.org/', lib=R_LIB_PATH)\n</code></pre>"},{"location":"drac/2025/04/17/submitting-job/","title":"Submitting job","text":"<p>Please do not run any computations on the login node. The login node resource (RAM\\CPU) is intended ONLY for tasks such as editing scripts and downloading\\transferring data. To learn how to properly submit jobs, please refer to the following guide: Digital Research Alliance of Canada.  Using the login node for computations can result in a warning from DRAC, and repeated violations lead to account suspension.</p>"},{"location":"drac/2025/04/17/submitting-job/#optimal-cpuram","title":"Optimal CPU\\RAM","text":"<p>Since we are using shared resources, please avoid submitting too many jobs  using excessive RAM/CPU (if your  job requested  30 GB RAM and only used 10 GB, DRAC adds 20 GB as wasted resources to your account  ). And DRAC may hold your jobs in the pending state if your resource wasted usage is too high. If you notice your jobs are pending for a long time longer than normal on Beluga (our main resource), consider canceling them and resubmitting on other DRAC resources like Narval or Cedar.</p> <p>If you're writing code in Python or R, run your code in multithreaded mode to improve performance and utilize all available CPU and RAM resources. I often use the command \"seff JOBID\" to check how much RAM and CPU my job used. This helps me request the appropriate resources for future runs. Many pipelines support multithreading, so make sure to enable it to fully utilize the available resources. When I'm unsure about a pipeline's resource usage, I usually run a small test job first to estimate the RAM usage. Based on that, I adjust the resource requests accordingly. Requesting 4 CPUs and 16 GB of RAM is typically optimal, and Beluga usually allocates these resources quickly. However, if you request 16 GB of RAM for 4 days and your job only uses 20% of it, you're effectively wasting 80% of the allocated resources. Don\u2019t worry if your job runs for only a short time\u2014that\u2019s perfectly fine. The real concern is when you submit many jobs at once, each reserving resources for several days. If those jobs end up wasting a large amount of CPU or RAM, DRAC may deprioritize your future jobs due to inefficient resource usage.</p>"},{"location":"drac/2025/04/07/vep/","title":"VEP","text":"<p>To use the Ensembl Variant Effect Predictor VEP in Beluga, follow the steps outlined below:</p>"},{"location":"drac/2025/04/07/vep/#step-to-run-vep-in-beluga","title":"Step to run VEP in Beluga","text":""},{"location":"drac/2025/04/07/vep/#vcf","title":"VCF","text":"<p>Specify the path of the VCF file as below:</p> <pre><code>VCF=./scratch/temp.vcf.gz\n</code></pre>"},{"location":"drac/2025/04/07/vep/#output","title":"Output","text":"<p>To save the output in the same directory as the VCF file, include the following in the job file. Otherwise, specify the output path in the OUTPUT parameter. <pre><code>OUTPUT=${OUTPUT:-${VCF/.vcf/.annotated_vep.vcf}}\n</code></pre></p>"},{"location":"drac/2025/04/07/vep/#reference","title":"Reference","text":"<p>You need to specify the reference and data root folders. Add the following lines to the job file:</p> <pre><code>FASTA=/cvmfs/ref.mugqic/genomes/species/Homo_sapiens.GRCh38/genome/Homo_sapiens.GRCh38.fa\nDIR_CACHE=/lustre03/project/6004655/COMMUN/data/VEP\nDIR_PLUGINS=${DIR_CACHE}/Plugins\n</code></pre>"},{"location":"drac/2025/04/07/vep/#custom-annotation","title":"Custom annotation","text":"<p>VEP can integrate custom annotation from standard format files into your results by using the --custom flag</p> <p>In th emain code, we will use CLINVAR_VCF and CLINVAR_FIELDS. </p> <p>VEP can incorporate custom annotations from standard format files into your results using the --custom flag see reference. In the main code, we will utilize CLINVAR_VCF and CLINVAR_FIELDS.</p> <pre><code>CLINVAR_VCF=${DIR_CACHE}/clinvar/clinvar_20240407.GRCh38.vcf.gz\nCLINVAR_FIELDS=\"ALLELEID,CLNDN,CLNREVSTAT,CLNSIG,CLNSIGCONF\"\n</code></pre>"},{"location":"drac/2025/04/07/vep/#plugins","title":"Plugins","text":"<p>VEP has several to extend, filter and manipulate the VEP output. see reference, for instance  the follwoing  are  CADD_SNV,CADD_INDEL,REVEL_DATA,ALPHAMISSENSE_DATA,SPLICEAI_SNV,SPLICEAI_INDEL,UTRANNOTATOR_DATA,PLI_DATA. </p> <pre><code>CADD_SNV=${DIR_PLUGINS}/CADD/GRCh38/gnomad.genomes.r3.0.snv.tsv.gz\nCADD_INDEL=${DIR_PLUGINS}/CADD/GRCh38/gnomad.genomes.r3.0.indel.tsv.gz\nREVEL_DATA=${DIR_PLUGINS}/REVEL/new_tabbed_revel_grch38.tsv.gz\nALPHAMISSENSE_DATA=${DIR_PLUGINS}/AlphaMissense/AlphaMissense_hg38.tsv.gz\nSPLICEAI_SNV=${DIR_PLUGINS}/SpliceAI/spliceai_scores.raw.snv.hg38.vcf.gz\nSPLICEAI_INDEL=${DIR_PLUGINS}/SpliceAI/spliceai_scores.raw.indel.hg38.vcf.gz\nUTRANNOTATOR_DATA=${DIR_PLUGINS}/UTRAnnotator/uORF_5UTR_GRCh38_PUBLIC.txt\nPLI_DATA=${DIR_PLUGINS}/pLI/pLI_values.txt\n</code></pre>"},{"location":"drac/2025/04/07/vep/#main-vep-command","title":"Main vep command","text":"<p>Here is the VEP code that generates the annotation file, provided you correctly define the paths for the VCF file, annotations, and plugins.</p> <pre><code>vep -i ${VCF} \\\n  --fork 4 \\\n  --show_ref_allele \\\n  --xref_refseq \\\n  --af_gnomade \\\n  --af_gnomadg \\\n  --af \\\n  --assembly GRCh38 \\\n  --fasta ${FASTA} \\\n  --cache \\\n  --dir_cache ${DIR_CACHE} \\\n  --cache_version 111 \\\n  --dir_plugins ${DIR_PLUGINS} \\\n  --buffer_size 20000 \\\n  --offline \\\n  --force_overwrite \\\n  --vcf \\\n  --compress_output bgzip \\\n  --symbol \\\n  --hgvs \\\n  --hgvsg \\\n  --pick_allele \\\n  --variant_class \\\n  --domains \\\n  --sift s \\\n  --polyphen s \\\n  --regulatory \\\n  --custom ${CLINVAR_VCF},ClinVar,vcf,exact,0,${CLINVAR_FIELDS} \\\n  --plugin CADD,${CADD_SNV},${CADD_INDEL} \\\n  --plugin REVEL,${REVEL_DATA} \\\n  --plugin AlphaMissense,file=${ALPHAMISSENSE_DATA} \\\n  --plugin SpliceAI,snv=${SPLICEAI_SNV},indel=${SPLICEAI_INDEL} \\\n  --plugin NMD \\\n  --plugin UTRAnnotator,file=${UTRANNOTATOR_DATA} \\\n  --plugin pLI,${PLI_DATA} \\\n  -o ${OUTPUT}\n</code></pre>"},{"location":"drac/2025/04/07/vep/#main-vep-command_1","title":"Main vep command","text":"<p>If you need to perform segregation after running VEP, consider using segpy. </p>"},{"location":"drac/2025/04/07/vep/#whole-code","title":"Whole CODE","text":"<pre><code>VCF=./scratch/temp.vcf.gz\nOUTPUT=${OUTPUT:-${VCF/.vcf/.annotated_vep.vcf}}\n\n\n# reference and data root folders\nFASTA=/cvmfs/ref.mugqic/genomes/species/Homo_sapiens.GRCh38/genome/Homo_sapiens.GRCh38.fa\nDIR_CACHE=/lustre03/project/6004655/COMMUN/data/VEP\nDIR_PLUGINS=${DIR_CACHE}/Plugins\n# custom anno files and fields\nCLINVAR_VCF=${DIR_CACHE}/clinvar/clinvar_20240407.GRCh38.vcf.gz\nCLINVAR_FIELDS=\"ALLELEID,CLNDN,CLNREVSTAT,CLNSIG,CLNSIGCONF\"\n# plugin data files\nCADD_SNV=${DIR_PLUGINS}/CADD/GRCh38/gnomad.genomes.r3.0.snv.tsv.gz\nCADD_INDEL=${DIR_PLUGINS}/CADD/GRCh38/gnomad.genomes.r3.0.indel.tsv.gz\nREVEL_DATA=${DIR_PLUGINS}/REVEL/new_tabbed_revel_grch38.tsv.gz\nALPHAMISSENSE_DATA=${DIR_PLUGINS}/AlphaMissense/AlphaMissense_hg38.tsv.gz\nSPLICEAI_SNV=${DIR_PLUGINS}/SpliceAI/spliceai_scores.raw.snv.hg38.vcf.gz\nSPLICEAI_INDEL=${DIR_PLUGINS}/SpliceAI/spliceai_scores.raw.indel.hg38.vcf.gz\nUTRANNOTATOR_DATA=${DIR_PLUGINS}/UTRAnnotator/uORF_5UTR_GRCh38_PUBLIC.txt\nPLI_DATA=${DIR_PLUGINS}/pLI/pLI_values.txt\n\n# main vep command\nvep -i ${VCF} \\\n  --fork 4 \\\n  --show_ref_allele \\\n  --xref_refseq \\\n  --af_gnomade \\\n  --af_gnomadg \\\n  --af \\\n  --assembly GRCh38 \\\n  --fasta ${FASTA} \\\n  --cache \\\n  --dir_cache ${DIR_CACHE} \\\n  --cache_version 111 \\\n  --dir_plugins ${DIR_PLUGINS} \\\n  --buffer_size 20000 \\\n  --offline \\\n  --force_overwrite \\\n  --vcf \\\n  --compress_output bgzip \\\n  --symbol \\\n  --hgvs \\\n  --hgvsg \\\n  --pick_allele \\\n  --variant_class \\\n  --domains \\\n  --sift s \\\n  --polyphen s \\\n  --regulatory \\\n  --custom ${CLINVAR_VCF},ClinVar,vcf,exact,0,${CLINVAR_FIELDS} \\\n  --plugin CADD,${CADD_SNV},${CADD_INDEL} \\\n  --plugin REVEL,${REVEL_DATA} \\\n  --plugin AlphaMissense,file=${ALPHAMISSENSE_DATA} \\\n  --plugin SpliceAI,snv=${SPLICEAI_SNV},indel=${SPLICEAI_INDEL} \\\n  --plugin NMD \\\n  --plugin UTRAnnotator,file=${UTRANNOTATOR_DATA} \\\n  --plugin pLI,${PLI_DATA} \\\n  -o ${OUTPUT}\n</code></pre>"},{"location":"drac/2025/04/07/vep/#how-use-individual-plugin","title":"How use individual plugin","text":"<p>If you want to use an individual plug-in, visit the Ensembl plug-in, download the desired plug-in, and add its path to your command. For example, to use CADD v1.7:</p> <pre><code>mkdir -p ~/scratch/CADD/GRCh38\ncd  ~/scratch/CADD/GRCh38\nwget https://krishna.gs.washington.edu/download/CADD/v1.7/GRCh38/whole_genome_SNVs.tsv.gz\nwget https://krishna.gs.washington.edu/download/CADD/v1.7/GRCh38/whole_genome_SNVs.tsv.gz.tbi\nwget https://krishna.gs.washington.edu/download/CADD/v1.7/GRCh38/gnomad.genomes.r4.0.indel.tsv.gz\nwget https://krishna.gs.washington.edu/download/CADD/v1.7/GRCh38/gnomad.genomes.r4.0.indel.tsv.gz.tbi\n</code></pre> <p>Redefind the path: </p> <pre><code>CADD_SNV=~/scratch/CADD/GRCh38/whole_genome_SNVs.tsv.gz\nCADD_INDEL=~/scratch/CADD/GRCh38/gnomad.genomes.r4.0.indel.tsv.gz\n</code></pre> <p>Then run main vep command. </p>"},{"location":"drac/2025/04/07/vep/#reference_1","title":"Reference","text":"<p>https://useast.ensembl.org/info/docs/tools/vep/script/index.html https://useast.ensembl.org/info/docs/tools/vep/script/vep_tutorial.html https://hpc.nih.gov/apps/VEP.html</p>"},{"location":"stat/stat_overview/","title":"Overview","text":"<p>UNDER CONSTRACTION </p> <p>This short book covers fundamental statistical material that help users to hands-on statistics. </p>"},{"location":"stat/linear_regression/mlr/","title":"Multiple Linear Regression","text":"<p>Basic idea: we have more than one covariate or predictor for modeling a dependent variabl</p> <p>Predicting Highway MPG in cars based on car specifications, 93 observations, 26 variables</p> <pre><code>&gt; names(car.data)\n [1] \"Manuf\"         \"Model\"         \"Type\"         \n [4] \"MinPrice\"      \"MidRangePrice\" \"MaxPrice\"     \n [7] \"CityMPG\"       \"HwyMPG\"        \"AirBags\"      \n[10] \"DriveTrain\"    \"Cyl\"           \"EngSize\"      \n[13] \"HPW\"           \"RPM\"           \"Rev\"          \n[16] \"ManTran\"       \"GasTank\"       \"PassCap\"      \n[19] \"Length\"        \"WheelBase\"     \"Width\"        \n[22] \"U-turn\"        \"RearSeat\"      \"Luggage\"      \n[25] \"Weight\"        \"Domest\"   \n</code></pre> <p>Consumer Reports: The 1993 Cars - Annual Auto Issue (April 1993), Yonkers, NY: Consumers Union When predicting Highway MPG, there are perhaps many informative predictors. we'll start by looking at two possible predictors, such as the vehicle Length and Width.</p> <pre><code>&gt; plot(car.data[,c(8,19,21)])   \n</code></pre> Image caption <p>Length and Width are both correlated with MPG (making them potentially good predictors), and it looks like these potential predictors of Length and Width are also correlated with each other.</p> <p>A multiple linear regression model with two independent variables:</p> \\[ Y_{i}=\\beta_{0} +\\beta_{1}x_{1i} +\\beta_{2}x_{2i}+ \\epsilon_{i} \\] <ul> <li>\\(Y_{i}\\) is the response or dependent variable for observation \\(i\\)\\</li> <li>\\(x_{1i}\\) is the observed predictor, explanatory variable, independent variable, covariate for variable 1 observation \\(i\\)\\</li> <li>\\(x_{2i}\\) is the observed predictor, explanatory variable, independent variable, covariate for variable 2 observation \\(i\\)\\</li> <li>\\(\\epsilon_{i}\\) is the error term with \\(\\epsilon_{i} \\stackrel{iid}{\\sim} N(0,\\sigma^2)\\)\\</li> </ul> <p>So, \\(E[Y_{i}|x_{1i},x_{2i}]=\\beta_{0} +\\beta_{1}x_{1i} +\\beta_{2}x_{2i}\\)</p> <p>In this model, we assume \\(Y\\) and \\(X_{1}\\) are linearly related, and Y and \\(X_{2}\\) are linearly related</p> <p>Return to MPG example</p> <p>After predicting MPG from Width, what \\% of the variability in MPG is \\underline{left to be explained}?</p> <pre><code>&gt; attach(car.data)\n&gt; lm.out=lm(HwyMPG ~ Width) \n&gt; summary(lm.out)$r.squared\n[1] 0.4100599\n</code></pre> <p>Does including Length as a predictor improve the overall \\% explained?</p> <pre><code>&gt; lm.out.2=lm(HwyMPG ~ Width + Length)\n&gt; summary(lm.out.2)$r.squared\n[1] 0.4108926\n</code></pre> <p>It explains only a {\\it little} bit more than Width alone</p> <p>From the scatterplot, it looked like Length and MPG (covariate and response) were negatively correlated.  But, Length was also correlated with Width (the other predictor variable in the model).</p> <pre><code>&gt; cor(HwyMPG,Length)\n[1] -0.5428974\n\n&gt; cor(Width,Length)\n[1] 0.8221479\n</code></pre> <p>So, there is a lot of redundant information in Length and Width when trying to predict MPG.  We gained little by including Length after Width was already in the model.</p> <p>A simple linear regression model including only MPG and Length provides an \\(R^{2}\\) of 0.30 (a `fair' predictor),  but this is not as high as when Width as the only predictor.</p> <pre><code>&gt; lm.out.Length=lm(HwyMPG ~ Length)\n&gt; summary(lm.out.Length)$r.squared\n[1] 0.2947376\n</code></pre> <p>For other variables or data sets, it may be the case where we may gain a lot from the inclusion of more predictors</p>"},{"location":"stat/linear_regression/mlr/#notation","title":"Notation","text":"<p>Lease squares estimates\\</p> <p>With \\(k\\) covariates, we just extend this to minimize\\</p> <p>\\(\\sum_{i=1}^{n} (Y_{i}-(b_{0}+b_{1}x_{1i}+\\ldots+b_{k}x_{ki}))^{2}\\)\\</p> <p>To get the parameter estimates, we take the derivative with respect to each regression coefficient, set the equations equal to 0, and solve.</p> <p>Estimate for \\(\\sigma^2\\)</p> <p>\\(\\sigma^2\\) is estimated as before with the residuals, but we now divide the RSS by (n-(k+1))=(n-k-1) since there are k+1 parameters estimated.\\</p> <p>\\(\\hat{\\sigma^2}=S_{E}^{2} = \\frac{RSS}{n-k-1}=\\frac{\\sum_{i=1}^{n}(Y_{i}-\\hat{Y}_{i})^{2}}{n-k-1}\\)\\</p> <ul> <li>SSE = RSS</li> <li>\\(E[\\frac{RSS}{n-k-1}]=\\sigma^2\\)</li> <li>\\(S_{E}\\) is the {\\it  standard error for the regression}</li> <li>\\(\\hat{\\sigma}=S_{E}=\\sqrt{S_{E}^{2}}\\)</li> <li>Another term often used, is MSE where \\(MSE=\\frac{SSE}{n-k-1}=\\frac{RSS}{n-k-1}\\)</li> </ul>"},{"location":"stat/linear_regression/nlr/","title":"Regression Model","text":""},{"location":"stat/linear_regression/nlr/#linear-models-linear-in-the-parameters","title":"Linear Models (linear in the parameters)","text":"<p>Simple linear relationship: Model the conditional mean response of a continuous variable using a linear relationship to a single continuous variable assuming normal errors</p> \\[ Y=\\beta_{0} +\\beta_{1}X + \\epsilon_{i}  \\quad epsilon\\sim N(n,\\sigma^2) \\] <p>Given X, Y has a normal distribution with a mean(center) of \ud835\udefd_0+\ud835\udefd_1 \ud835\udc4b and a variance of \ud835\udf0e^2 . Also, it can be written as  $$ Y|X \\sim N(\\beta_{0} +\\beta_{1}X,\\sigma^2) $$</p>"},{"location":"stat/linear_regression/nlr/#quadratic-relationship","title":"Quadratic relationship:","text":"<p>Model the conditional mean response of a continuous variable as a quadratic relationship to a single continuous variable (this is still a linear model as it\u2019s linear in the parameters) </p> \\[ Y=\\beta_{0} +\\beta_{1}X + \\beta_2X^2 \\epsilon \\quad \\epsilon\\sim N(n,\\sigma^2) \\]"},{"location":"stat/linear_regression/nlr/#multiple-linear-relationships","title":"Multiple linear relationships","text":"<p>Model the conditional mean response of a continuous variable as a linear relationship with each of two continuous variables (no interaction) </p> \\[ Y=\\beta_{0} +\\beta_{1}X_1 + \\beta_2X_2 \\epsilon \\quad \\epsilon\\sim N(n,\\sigma^2) \\]"},{"location":"stat/linear_regression/nlr/#non-linear-models","title":"Non-Linear Models","text":"<p>A specific relationship:  $$ Y=\\beta_{0} +\\beta_{1}X^{\\beta_3} + \\beta_2X_2^{\\beta_4} \\epsilon \\quad \\epsilon\\sim N(n,\\sigma^2) $$</p>"},{"location":"stat/linear_regression/nlr/#nonparametric-regression","title":"Nonparametric regression","text":"<p>The Nonparametric regression estimate the function $$ Y_i=f(X_i)+\\epsilon_i  $$</p> <p>LOWESS (locally weighted scatterplot smoother) </p> <p>The predicted  \ud835\udc4c_\ud835\udc56 for a given \ud835\udc4b_\ud835\udc56  is determined by considering only \u2018local\u2019 points in \u2018window\u2019 around  \ud835\udc4b_\ud835\udc56.  - Often a simple linear regression is fit to the local points, and the prediction falls in this line - Researcher chooses width of window</p>"},{"location":"stat/linear_regression/others/","title":"Other analysis","text":"<p>The type of data will affect how the data is modeled and the choice of analysis</p> <ul> <li>Binary response with covariate predictors: Logistic regression </li> <li>Relationship between categorical / ordinal variables Contingency tables</li> <li>Relationship between a quantitative dependent variable (Y) and qualitative predictor:  anova</li> <li>Response is a count (Poisson distribution) and the Poisson distribution mean is dependent on the covariates:  Poisson regression </li> </ul>"},{"location":"stat/linear_regression/overview/","title":"Overview","text":"<p>Regression analysis is a class of statistical methods for </p> <ul> <li>Examining the relationships between measurable variables, such as the connection between blood pressure and age.</li> <li>Utilizing known values of certain variables to predict the values of other variables for the same individuals, such as using a person\u2019s age, cholesterol level, and weight to estimate their blood pressure.</li> </ul> <p>Regression analysis examines the conditional distribution of Y\u2014or specific aspects of it, such as the mean\u2014based on a function of the X\u2019s. It models the general relationship between X and Y, incorporating a random error term (\\(\\epsilon\\)) to account for variability not explained by X.</p> Regression Model <p>The setup of your regression model largely depends on the specific goals of your analysis. Inference vs. Prediction </p> <p>Primary goal is to predict the outcomes for new data </p> <p>Y = patient\u2019s risk for severe side effects  X\u2019s = characteristics of patient\u2019s blood samples</p> <p>Y = Positive/negative response to marketing campaign X\u2019s = customer demographic variables</p> <p>Inference: The goal is to understand the relationship between X\u2019s and Y. Which predictors are significant? Can the relationship be effectively modeled?</p> <p>Y = product sales X\u2019s = advertising budgets (TV, radio, newspaper)</p> <p>Y = probability of product purchase X\u2019s = price, store location, discounts, competitor\u2019s price</p>"},{"location":"stat/linear_regression/slr/","title":"Simple Linear Regression","text":"<p>Methods for analyzing the relationship between two or more quantitative variables, such as examining the impact of lead exposure on school performance or predicting the force at which a metal alloy rod bends based on its iron content.</p> <p>The basic model</p> \\[Y_{i}=\\beta_{0} +\\beta_{1}x_{i} + \\epsilon_{i}\\] <ul> <li>\\(Y_{i}\\) is the response of dependent variable</li> <li>\\(x_{i}\\) is the observed predictor, explanatory variable, independent variable, covariate</li> <li>\\(x_{i}\\) is treated as a fixed quantity (or if random it is conditioned upon)</li> <li>\\(\\epsilon_{i}\\) is the error term </li> <li>\\(\\epsilon_{i}\\) are iid \\(N(0,\\sigma^2)\\)</li> </ul> <p>So, \\(E[Y_{i}]=\\beta_{0} +\\beta_{1}x_{i} +0 =\\beta_{0} +\\beta_{1}x_{i}\\) </p> <p>Key assumptions</p> <ul> <li>Linear relationship (between Y and x. *we say the relationship between Y and x is linear if the means of the conditional distributions of Y\\(|\\)x lie on a straight lin</li> <li>independent errors ((independent observations in SLR)</li> <li>Constant variance of error</li> <li>Normally distributed errors</li> </ul>"},{"location":"stat/linear_regression/slr/#interpreting-the-model","title":"Interpreting the model","text":"<p>The model can also be expressed as:</p> \\[ Y_{i}|X_{i}=x_{i} \\; \\; \\sim \\; \\; N(\\beta_{0} +\\beta_{1}x_{i},\\sigma^2) \\] <ul> <li>Mean of \\(Y\\) given \\(X=x\\) is \\(\\beta_{0} +\\beta_{1}x\\) (known as conditional mean).</li> <li>\\(\\beta_{0} +\\beta_{1}x\\) is the mean value of all the \\(Y\\)'s for the given value of \\(x\\).</li> <li>\\(\\beta_{0}\\) is conditional mean when \\(x\\)=0.</li> <li>\\(\\beta_{1}\\) is slope, change in mean of \\(Y\\) per 1 unit change in \\(x\\).</li> <li>\\(\\sigma^2\\) is the variation of responses at \\(x\\) (i.e.~dispersion around conditional mean).</li> </ul>"},{"location":"stat/linear_regression/slr/#estimation-of-beta_0-andbeta_1","title":"Estimation of \\(\\beta_{0}\\) and\\(\\beta_{1}\\)","text":"<p>We wish to use the sample data to  estimate the population parameters: the slope \\(\\beta_{1}\\) and the intercept \\(\\beta_{0}\\).  Least squares estimation:</p> <ul> <li> <p>choose \\(\\hat{\\beta_{0}}=b_{0}\\) and \\(\\hat{\\beta_{1}}=b_{1}\\). such that we minimize the sum of the squared residuals, i.e.~minimize \\(\\sum_{i=1}^{n}(Y_{i}-\\hat{Y}_{i})^{2}\\).</p> </li> <li> <p>minimize  \\(\\(g(b_{0},b_{1})=\\sum_{i=1}^{n}(Y_{i}-(b_{0}+b_{1}x_{i}))^{2}\\)\\)</p> </li> <li> <p>Take derivative of \\(g(b_{0},b_{1})\\) with respect to \\(b_{0}\\) and \\(b_{1}\\), set equal to zero, and solve.</p> </li> </ul> <p>Results: </p> \\[ b_{0}=\\bar{Y}-b_{1}\\bar{x} \\] \\[ b_{1}=\\frac{\\sum_{i=1}^{n} (x_{i}-\\bar{x})(Y_{i}-\\bar{Y})}{\\sum_{i=1}^{n} (x_{i}-\\bar{x})^{2}} \\] <p>The point \\((\\bar{x},\\bar{Y})\\) will always be on the least squares line</p> <ul> <li>\\(b_{0}\\) and \\(b_{1}\\) are best linear unbiased estimators (best meaning smallest variance estimator)</li> </ul> <p>Notation for fitted line:</p> \\[\\hat{Y}_{i}=\\hat{\\beta}_{0} + \\hat{\\beta}_{1} x_{i}\\] \\[\\hat{Y}_{i}=b_{0} + b_{1} x_{i}\\] <p>Predicted (fitted) value: \\(\\hat{Y}_{i}=b_{0}+b_{1}x_{i}\\)</p> <p>residual: \\(e_{i}=Y_{i}-\\hat{Y}_{i}\\)</p> <p>The least squares regression line minimizes the residual sums of squares (RSS)=\\(\\sum_{i=1}^{n}(Y_{i}-\\hat{Y}_{i})^{2}\\)</p>"},{"location":"stat/linear_regression/slr/#example-cigarette-data","title":"Example : Cigarette data","text":"<p>Measurements of weight and tar, nicotine, and carbon monoxide content are given for 25 brands of domestic cigarettes</p> <pre><code>VARIABLE DESCRIPTIONS:\nBrand name \nTar content (mg)\nNicotine content (mg)\nWeight (g)\nCarbon monoxide content (mg)\n</code></pre> <p><pre><code>&gt; cig.data=as.data.frame(read.delim(\"cig.txt\",sep=\" \",\n                                         header=FALSE))\n&gt; dim(cig.data)\n[1] 25  5\n\n## This data set had no header, so I will assign \n## the column names here:\n&gt; dimnames(cig.data)[[2]]=c(\"Brand\",\"Tar\",\"Nic\",\n                                         \"Weight\",\"CO\")\n&gt; head(cig.data)\n          Brand  Tar  Nic Weight   CO\n1        Alpine 14.1 0.86 0.9853 13.6\n2 Benson-Hedges 16.0 1.06 1.0938 16.6\n3    BullDurham 29.8 2.03 1.1650 23.5\n4   CamelLights  8.0 0.67 0.9280 10.2\n5       Carlton  4.1 0.40 0.9462  5.4\n6  Chesterfield 15.0 1.04 0.8885 15.0\n</code></pre> <pre><code>&gt; plot(cig.data$Tar,cig.data$Nic)\n</code></pre></p> Scatter plot <pre><code>## Fit a simple linear regression of Nicotine on Tar.\n&gt; lm.out=lm(Nic~Tar,data=cig.data)\n\n## Get the estimated slope and intercept:\n&gt; lm.out$coefficients\n(Intercept)         Tar \n 0.13087532  0.06102854 \n</code></pre> <pre><code>## Add the fitted line to the original plot:\n&gt; plot(cig.data$Tar,cig.data$Nic)\n&gt; abline(lm.out)\n</code></pre> Image caption Image caption <p>Recall the model: </p> <p>\\(Y_{i}=\\beta_{0} +\\beta_{1}x_{i} + \\epsilon_{i}\\) with \\(\\epsilon_{i} \\stackrel{iid}{\\sim} N(0,\\sigma^2)\\)</p> <p>We use the sum of the squares of the residuals to estimate \\(\\sigma^2\\)</p> <ul> <li>RSS \\(\\equiv\\) Residual sum of squares</li> <li>SSE \\(\\equiv\\) Sum of squared errors</li> <li> <p>RSS \\(\\equiv\\) SSE</p> </li> <li> <p>\\(\\hat{\\sigma^2}= \\frac{RSS}{n-2}=\\frac{\\sum_{i=1}^{n}(Y_{i}-\\hat{Y}_{i})^{2}}{n-2}\\)$</p> </li> <li> <p>RSS = \\(\\sum_{i=1}^{n}(Y_{i}-\\hat{Y}_{i})^{2}\\)</p> </li> </ul> <p>\\(E[\\frac{RSS}{n-2}]=\\sigma^2\\), \\(\\hat{\\sigma}\\) = \\(S_{E}=\\sqrt{S_{E}^{2}}\\)  is called the standard error for the regression</p>"},{"location":"stat/linear_regression/slr/#total-sums-of-squares-tss","title":"Total sums of squares (TSS)","text":"<p>Total sums of squares (TSS) quantifies the overall squared distance of the \\(Y\\)-values from the overall mean of the responses \\(\\bar{Y}\\).</p> Image caption <p>Which leads to the equation</p> \\[\\sum_{i=1}^{n}(Y_{i}-\\bar{Y})^{2}=\\sum_{i=1}^{n}(Y_{i}-\\hat{Y}_{i})^{2} + \\sum_{i=1}^{n}(\\hat{Y}_{i}-\\bar{Y})^{2}\\] \\[TSS=RSS + RegSS\\] <p>where \\(RegSS\\) is the  regression sum of squares. Total variability has been decomposed into <code>explained</code> and <code>unexplained</code> variability. In general, when the proportion of total variability that is explained is high, we have a good fitting model</p> <p>The \\(R^{2}\\) value (coefficient of determination):</p> <ul> <li>the proportion of variation in the response that is explained by the model.</li> <li>\\(R^{2}=\\frac{RegSS}{TSS}\\).</li> <li>\\(R^{2}=1-\\frac{RSS}{TSS}\\).</li> <li>also stated as \\(r^{2}\\) in simple linear regression.</li> <li>\\(0 \\leq R^{2}\\leq 1\\).</li> <li>\\(R^{2}\\) near 1 suggests a good fit to the data.</li> <li>if \\(R^{2}=1\\), aLL points fall it exactly on the line. </li> <li>different disciplines have different views on what is a {\\it high} \\(R^{2}=1\\), in other words what is a good model. </li> </ul> <p>Note: social scientists may get excited about an \\(R^{2}\\) near 0.30, a researcher with a designed experiment may want to see an \\(R^{2}\\) near 0.80</p> <p>## Analysis of Variance (ANOVA)  The decomposition of total variance into parts is part of ANOVA As was stated before: \\(TSS=RSS + RegSS\\)</p> Image caption Image caption <p>Get the \\(R^{2}\\) value (2 ways shown):</p> <pre><code>&gt; summary(lm.out)\nlook for....  Multiple R-Squared: 0.9538 \n\n&gt; summary(lm.out)$r.squared\n[1] 0.9537625\n</code></pre>"},{"location":"stat/linear_regression/slr/#correlation-coefficient","title":"Correlation coefficient","text":"<p>The  correlation coefficient r measures the strength of a  linear relationship</p> \\[ \\begin{aligned} r&amp;=&amp;\\frac{\\sum_{i=1}^{n} (X_{i}-\\bar{X})(Y_{i}-\\bar{Y})}{\\sqrt{\\sum_{i=1}^{n} (X_{i}-\\bar{X})^{2}\\sum_{i=1}^{n} (Y_{i}-\\bar{Y})^{2}}} \\\\ &amp;=&amp;\\frac{\\sqrt{\\frac{\\sum_{i=1}^{n} (X_{i}-\\bar{X})^{2}}{n-1}}}{\\sqrt{\\frac{\\sum_{i=1}^{n} (Y_{i}-\\bar{Y})^{2}}{n-1}}} \\cdot b_{1} \\\\ &amp;=&amp;\\frac{S_{X}}{S_{Y}} \\cdot b_{1} \\end{aligned} \\] <ul> <li>it is the standardized slope, a unitless measure, </li> <li>can be thought of as the value we would get for the slope if the standard deviations of \\(X\\) and \\(Y\\) were equal similar spreads</li> <li>would be the slope if \\(X\\) and \\(Y\\) had been standardized before fitting the regression</li> <li>\\(-1 \\leq r \\leq 1\\)</li> <li>\\(r\\) near -1 or +1 shows a strong linear relationship</li> <li>a negative (positive) \\(r\\) is associated with an estimated negative (positive) slop</li> <li>the sample correlation coefficient \\(r\\) estimates the population correlation coefficient \\(\\rho\\).</li> <li>\\(r\\) is NOT used to measure strength of a curved line</li> </ul>"},{"location":"stat/linear_regression/slr/#common-mistake","title":"Common mistake","text":"<p>People often think that as the estimated slope of the regression line, \\(\\hat{\\beta}_{1}\\), gets larger (steeper), so does \\(r\\).  But \\(r\\) really measures how close all the data points are to our estimated regression line.</p> <p>You could have a steep fitted line with a small \\(r\\) (noisy relationship), or a fairly flat fitted line with large \\(r\\) (less noisy relationship).</p> <p>This can be confusing because when the estimated slope is actually 0, then \\(r\\) is 0 no matter how close the points are to the regression line (see formulas for \\(r\\) on the previous pages).</p>"},{"location":"stat/logistic_regression/ancova/","title":"logistics regression ANCOVA","text":"<p>When at least one of independent variable is categorical, we nned to use Analysis of covariance (ANCOVA), let assume we want to stduy the relateion betwwen  breast cancer (Menopause: 0 (not present) or 1 (present)), and age, and sport activity.  obviously, the age is continuous and sport activity can be consider as categorical. </p>"},{"location":"stat/logistic_regression/introduction/","title":"Introduction","text":"<p>When the response variable is a binary variable, such as 0 or 1, live or die,  fail or succeed,  we approach our modeling a little differently.  Let look at a real example: study the effect of the level of lead in the soil in the subject\u2019s backyard (X) on lead blood level (Y). The level of lead is continous but the lead blood level can be either high lead blood level(1) or low lead blood level(0). If you plot the X vs Y, you get </p> Image caption <p>Consider the usual regression model:</p> \\[Y_{i}=\\beta_0 + \\beta_1 x_{i} +\\epsilon_{i}\\] <p>The fitted model and residuals: $$ \\hat{Y}=0.3178 + 0.0003x $$</p> <p>All sorts of violations here:</p> Image caption <p>Let trust the model and find the prediction for x=3000, $$ \\hat{Y}_{x=3000}=1.14 $$, and this is not possibly an average of the 0s and 1s. We need a better approach, tp model 0-1 response regression: we can model on \\(P(Y=1)\\): We will consider this probability of getting a 1 given the x-value(s) in our modeling  $$ \\pi_i=P(Y_i=1| X_i)=1-P(Y_i=0| X_i) $$</p> <p>actually by a transformation of this prob ability \\(\\pi_i\\) that we will use as our response in the regression model.</p>"},{"location":"stat/logistic_regression/introduction/#odds-of-an-event","title":"Odds of an Event","text":"<p>Let discuss the odd of en even: \\n We flip two fair coins, the the probabilities of two heads or not two heads are $$ P(two heads)=\u00bc $$ $$ P(not two heads)=\u00be $$</p> <p>The odds in favor of getting two heads is:</p> \\[ odds=\\frac{P(two heads)}{P(not two heads)}=\\frac{1/4}{3/4}=1/3 \\] <p>referred to as 1 to 3 odds. You\u2019re 3 times as likely to not get 2 heads as you are to get 2 heads</p>"},{"location":"stat/logistic_regression/introduction/#odds-ratio","title":"odds ratio","text":"<p>Let consider a binary variable \\(Y\\) (2 possible outcomes), odds in favor of Y=1 is</p> \\[ \\frac{P(Y=1)}{P(Y=0)}=\\frac{P(Y=1)}{1-P(Y=1)} \\] <p>For example, if P(heart attack)=0.0018, then the odds of a heart attack is</p> \\[ \\frac{0.0018}{0.9982}=\\frac{0.0018}{1-0.0018}=0.001803 \\] <p>The ratio of the odds for two di\ufb00erent groups is also a quantity of interest. For example, consider heart attacks for \u201cmale nonsmoker vs. male smoker\u201d. </p> <p>Suppose P(heart attack)=0.0036 for a male smoker, and P(heart attack)=0.0018 for a male nonsmoker.  Then, the odds ratio (O.R.) for a heart at- tack in nonsmoker vs. smoker is</p> \\[ \\begin{aligned} O.R. &amp;=&amp; \\frac{\\mbox{odds of a heart attack for non-smoker}}{\\mbox{odds of a heart attack for smoker}} \\\\ &amp;=&amp; \\frac{\\left(\\frac{Pr(\\mbox{heart attack$|$non-smoker})}{1-Pr(\\mbox{heart attack$|$non-smoker})}\\right)}{\\left(\\frac{Pr(\\mbox{heart attack$|$smoker})}{1-Pr(\\mbox{heart attack$|$smoker})}\\right)} \\\\ &amp;=&amp;\\frac{\\left(\\frac{0.0018}{0.9982}\\right)}{\\left(\\frac{0.0036}{0.9964}\\right)}=0.4991 \\end{aligned} \\] <p>Interpretation of the odds ratio for binary 0-1</p> <ul> <li>If O.R.= 1.0, then P(Y = 1) is the same in both samples</li> <li>If O.R.&lt;1.0, then P(Y = 1) is less in the numerator group than in the denominator group</li> <li>O.R.= 0 if and only if P(Y = 1) = 0 in numerator sample</li> </ul>"},{"location":"stat/logistic_regression/introduction/#logistic-regression","title":"Logistic Regression","text":"<p>The response variable we will model is a transformation of \\(P(Y_i = 1)\\) for a given \\(X_i\\). The transformation is the logit transformation $$ logit(a)=ln \\left(\\frac{a}{1-a}\\right) $$</p> <p>The response variable we will use: $$ logit[P(Y_{i}=1)]=ln \\left( \\frac{P(Y_{i}=1)}{1-P(Y_{i}=1)} \\right) $$ This is the log\\(_{e}\\) of the odds that \\(Y_{i}=1\\). Notice: \\(P(Y_{i}=1) \\in (0,1)\\)</p> <p>This response on the left isn't <code>bounded</code>  by [0,1] eventhough the Y-values themselves are (having the response bounded by [0,1] was a problem before). The response on the left can feasibly be any positive or negative quantity. This a nice characteristic because the right side of the equation can `potentially' give any possible predicted value \\(-\\infty\\) to \\(\\infty\\).The logistic regression model is a GENERALIZED LINEAR MODEL. Linear model on  the right, something other than the usual continuous Y on the left.</p> <p>Let's look at the fitted logistic regression model for the lead level data with one \\(X\\) covariate</p> \\[ ln \\left( \\frac{P(Y_{i}=1)}{1-P(Y_{i}=1)} \\right) = \\hat{\\beta}_{0} + \\hat{\\beta}_{1}X_{i}= -1.5160 + 0.0027 \\; X_{i} \\] Image caption <p>The curve represents the \\(E(Y_{i}|x_{i})\\) $$ E(Y_{i}|x_{i})=0\\cdot P(Y_{i}=0|x_{i})+1\\cdot P(Y_{i}=1|x_{i}) =P(Y_{i}=1|x_{i}$$</p> <p>We can manipulate the regression model to put it in terms of \\(P(Y_{i}=1)=E(Y_{i})\\) If we take this regression model</p> \\[ ln \\left( \\frac{P(Y_{i}=1)}{1-P(Y_{i}=1)} \\right) = -1.5160 + 0.0027  X_{i} \\] <p>and solve for \\(P(Y_{i}=1)\\) we get</p> \\[P(Y_{i}=1) = \\frac{exp(-1.5160 + 0.0027 \\; X_{i})}{1+exp(-1.5160 + 0.0027 \\; X_{i})}\\] <p>Because our \\(\\beta_{1}\\) is positive,</p> <ul> <li>As \\(X\\) gets larger, \\(P(Y_{i}=1)\\) goes to 1.</li> <li>As \\(X\\) gets smaller, \\(P(Y_{i}=1)\\) goes to 0.</li> </ul> <p>The fitted curve, i.e.the function of \\(X_{i}\\) on the right, is S-shaped (sigmoidal)</p>"},{"location":"stat/logistic_regression/multiple_covariate/","title":"Multiple covariate Model","text":"<p>In general,  when the response variable is binary, We model the log of the odds for Yi = 1</p> \\[ ln \\left( \\frac{P(Y_{i}=1)}{1-P(Y_{i}=1)} \\right) = \\beta_{0} + \\beta_{1}X_{1i}+\\cdots + \\beta_{k}X_{ki} \\] <p>Which can be converted to</p> \\[ \\begin{aligned} P(Y_{i}=1) &amp;=&amp; \\frac{exp(\\beta_{0} + \\beta_{1}X_{1i}+\\cdots + \\beta_{k}X_{ki})}{1+exp(\\beta_{0} + \\beta_{1}X_{1i}+\\cdots + \\beta_{k}X_{ki})}\\\\ &amp;=&amp; \\frac{1}{1+exp[-(\\beta_{0} + \\beta_{1}X_{1i}+\\cdots + \\beta_{k}X_{ki})]} \\end{aligned} \\] <p>Unlike OLS regression, logistic regression does not assume...</p> <ul> <li>linearity between the independent variables and the dependent.</li> <li>normally distributed errors.</li> <li>homoscedasticity.</li> </ul> <p>It does assume...</p> <ul> <li>we have independent observations</li> <li>that the independent variables be linearly related to the logit of the dependent variable (somewhat difficult to check</li> </ul>"},{"location":"stat/logistic_regression/one_covariate/","title":"One covariate Model","text":""},{"location":"stat/logistic_regression/one_covariate/#introduction","title":"Introduction","text":"<p>In the general model with one covariate:</p> \\[ ln \\left( \\frac{P(Y_{i}=1)}{1-P(Y_{i}=1)} \\right) = \\beta_{0} + \\beta_{1} X_{i} \\] <p>which means</p> \\[ \\begin{aligned} P(Y_{i}=1) &amp;=&amp; \\frac{exp(\\beta_{0} + \\beta_{1}  X_{i})}{1+exp(\\beta_{0} + \\beta_{1}  X_{i})} \\\\ &amp;=&amp; \\frac{1}{1+exp[-(\\beta_{0} + \\beta_{1}  X_{i})]} \\end{aligned} \\] <ul> <li>If \\(\\beta_{1}\\) is positive, we get the S-shape that goes to 1 as \\(X_{i}\\) goes to \\(\\infty\\) and goes to 0 as \\(X_{i}\\) goes to \\(-\\infty\\) (as in the lead example).</li> <li>If \\(\\beta_{1}\\) is negative, we get the opposite S-shape that goes to 0 as \\(X_{i}\\) goes to \\(\\infty\\) and goes to 1 as \\(X_{i}\\) goes to \\(-\\infty\\).</li> </ul> <p>Another way to think of logistic regression is that we're modeling a Bernoulli random variable occurring for each \\(X_{i}\\), and the Bernoulli parameter \\(\\pi_{i}\\) depends on the covariate value.</p> <p>Then,  \\(Y_{i}|X_{i} \\sim Bernoulli(\\pi_{i})\\) where  \\(\\pi_{i}\\) represents \\(P(Y_{i}=1|X_{i})\\) \\(E(Y_{i}|X_{i})=\\pi_{i}\\) and  \\(V(Y_{i}|X_{i})=\\pi_{i}(1-\\pi_{i})\\). </p> <p>We're thinking in terms of the conditional distribution of \\(Y|X\\) (we don't have constant variance across the \\(X\\) values, mean and variance are tied together).</p> <p>Writing \\(\\pi_{i}\\) as a function of \\(X_{i}\\)</p> \\[\\pi_{i} = \\frac{exp(\\beta_{0} + \\beta_{1}  X_{i})}{1+exp(\\beta_{0} + \\beta_{1}  X_{i})}\\]"},{"location":"stat/logistic_regression/one_covariate/#interpretation-of-parameters","title":"Interpretation of parameters","text":"<p>For the lead levels example.</p>"},{"location":"stat/logistic_regression/one_covariate/#intercept-beta_0","title":"Intercept \\(\\beta_{0}\\)","text":"<p>When \\(X_{i}=0\\), there is no lead in the soil in the backyard.  Then, $$ ln \\left( \\frac{P(Y_{i}=1)}{1-P(Y_{i}=1)} \\right) = \\beta_{0}  $$</p> <p>So, \\(\\beta_{0}\\) is the log-odds that a randomly selected child with no lead in their backyard has a high lead blood level. Or, \\(\\pi_{i}=\\frac{e^{\\beta_{0}}}{1+e^{\\beta_{0}}}\\) is the chance that a kid with no lead in their backyard has high lead blood level.</p> <p>For this data, \\indent \\tab \\tab \\(\\hat{\\beta}_{0}=-1.5160\\) \\tab or \\tab \\(\\hat{\\pi_{i}}=0.1800\\)</p>"},{"location":"stat/logistic_regression/one_covariate/#coefficient-beta_1","title":"Coefficient \\(\\beta_{1}\\)","text":"<p>Consider the log\\(_{e}\\) of the odds ratio (\\(O.R.\\)) of having high lead blood levels for the following 2 groups... -  1) those with exposure level of \\(x\\) -  2) those with exposure level of \\(x+1\\)</p> \\[ \\begin{aligned} log_{e} \\left( \\frac{\\frac{\\pi_{2}}{1-\\pi_{2}}}{\\frac{\\pi_{1}}{1-\\pi_{1}}} \\right)&amp;=log_{e} \\left( \\frac{e^{\\beta_{0}}e^{\\beta_{1}(x+1)}}{e^{\\beta_{0}}e^{\\beta_{1}x}} \\right) &amp;=&amp;log_{e}\\left( e^{\\beta_{1}} \\right) &amp;=&amp;\\beta_{1} \\end{aligned} \\] <p>\\(\\beta_{1}\\) is the log\\(_{e}\\) of \\(O.R.\\) for a 1 unit increase in \\(x\\).</p> <p>Or, un-doing the log,  \\(e^{\\beta_{1}}\\) is the \\(O.R.\\) comparing the two groups. For this data \\(\\hat{\\beta}_{1}=0.0027\\)  or  \\(e^{0.0027}=1.0027\\) A 1 unit increase in X increases the odds of having a high lead blood level by a factor of 1.0027. Though this value is small, the range of the  \\(X\\) values is large(40 to 5255), so it can have a substantial impact when you consider the full spectrum of \\(x\\) values.</p>"},{"location":"stat/logistic_regression/one_covariate/#prediction","title":"Prediction","text":"<p>What is the predicted probability of high lead blood level for a child with \\(X=500\\).</p> \\[ \\begin{aligned} P(Y_{i}=1) &amp;=&amp; \\frac{exp(-1.5160 + 0.0027  X_{i})}{1+exp(-1.5160 + 0.0027  X_{i})} \\\\ &amp;=&amp; \\frac{1}{1+exp[-(-1.5160 + 0.0027  X_{i})]} \\\\ &amp;=&amp; \\frac{1}{1+exp[1.5160 - 0.0027 \\times 500]} \\\\  &amp;=&amp;   0.4586 \\\\ \\end{aligned} \\] <p>What is the predicted probability of high lead blood level for a child with \\(X=4000\\). $$ P(Y_{i}=1) = \\frac{1}{1+exp[1.5160 - 0.0027 \\times 4000]} =  0.9999 $$</p> <p>What is the predicted probability of high lead blood level for a child with \\(X=0\\).</p> \\[ P(Y_{i}=1) = \\frac{1}{1+exp[1.5160]} =  0.1800 \\] <p>So, there's still a chance of having high lead blood level even when the backyard doesn't have any lead.  This is why we don't see the low-end of our fitted S-curve go to zero.</p>"},{"location":"stat/logistic_regression/overview/","title":"Overview","text":"<ul> <li>Introduction</li> <li>One covariate</li> <li>multiple covariate</li> <li>ANCOVA</li> </ul>"},{"location":"blog/archive/2025/","title":"2025","text":""},{"location":"blog/archive/2024/","title":"2024","text":""},{"location":"blog/category/bioinfo/","title":"Bioinfo","text":""},{"location":"blog/category/linux/","title":"linux","text":""},{"location":"blog/category/awk/","title":"awk","text":""},{"location":"blog/category/sort/","title":"sort","text":""},{"location":"blog/category/sed/","title":"sed","text":""},{"location":"blog/category/ssh/","title":"ssh","text":""},{"location":"blog/category/website/","title":"website","text":""},{"location":"blog/category/markdown/","title":"Markdown","text":""},{"location":"blog/page/2/","title":"Index","text":""},{"location":"blog/archive/2024/page/2/","title":"2024","text":""},{"location":"drac/archive/2025/","title":"2025","text":""},{"location":"drac/archive/2024/","title":"2024","text":""},{"location":"drac/category/drac/","title":"DRAC","text":""},{"location":"drac/category/annotation/","title":"Annotation","text":""},{"location":"drac/category/hail/","title":"Hail","text":""},{"location":"drac/category/ssh/","title":"ssh","text":""},{"location":"drac/category/hpc/","title":"hpc","text":""},{"location":"drac/category/installing-python-library/","title":"Installing Python library","text":""},{"location":"drac/category/installing-r-library/","title":"Installing R library","text":""}]}